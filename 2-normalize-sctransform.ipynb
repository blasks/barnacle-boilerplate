{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137a6624-8324-4ae1-b8a0-e783b4b7bf47",
   "metadata": {},
   "source": [
    "# Step 2: Normalize your data using sctransform\n",
    "\n",
    "Use this notebook to normalize your data using the [sctransform](https://satijalab.org/seurat/articles/sctransform_vignette) package. \n",
    "\n",
    "Please note that the sctransform package is written in R. Therefore, in order to run this notebook you will first need to [install R]() on your system, as well as [sctransform version 0.4.1](https://github.com/satijalab/sctransform) and it's corresponding dependencies (including the optional dependency [glmGamPoi](https://github.com/const-ae/glmGamPoi)). \n",
    "\n",
    "Also note that your raw data input should be a csv file arranged using [tidy format](https://tidyr.tidyverse.org/articles/tidy-data.html). At a minimum your input csv should have five columns:\n",
    "1. A column that corresponds to the first mode of your tensor. In metatranscriptomic data this column might indicate gene ID.\n",
    "    - This first mode should generally be the longest in your tensor, and the one that corresponds to the variable you want clustered (e.g. genes in the case of metatranscriptomics data). The sparsity penalty (`lambda`) will be applied to this mode.\n",
    "1. A column that corresponds to the second mode of your tensor. In metatranscriptomic data this column might indicate taxon ID.\n",
    "1. A column that corresponds to the third mode of your tensor. This column should indicate sample ID.\n",
    "    - **IMPORTANT: Sample IDs should be identical for different replicates of the same sample condition (see example below).**\n",
    "1. A column that indicates the replicate ID of the sample.\n",
    "1. A column that corresponds to the data variable. For raw metatranscriptomic data this column might contain read counts.\n",
    "\n",
    "Here's a snippet of how an example csv might be arranged:\n",
    "\n",
    "| gene_id | taxon_id   | sample_id | replicate | residual |\n",
    "|---------|------------|-----------|-----------|----------|\n",
    "| K03839  | P. marinus | sample1   | A         | 3.02     |\n",
    "| K03839  | P. marinus | sample1   | B         | 3.31     |\n",
    "| K03839  | P. marinus | sample1   | C         | 3.18     |\n",
    "| K03839  | P. marinus | sample2   | A         | -1.24    |\n",
    "| ...     | ...        | ...       | ...       | ...      |\n",
    "| K03320  | S. marinus | sample9   | C         | 0.05     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086abf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# python packages\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rpy2\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# rpy2 imports\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.ipython.ggplot import image_png\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# load rpy2 extension for ipython\n",
    "pandas2ri.activate()\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install & import sctransform and other r package dependencies\n",
    "\n",
    "# check if sctransform is installed\n",
    "if not ro.packages.isinstalled('sctransform'):\n",
    "    # select CRAN mirror\n",
    "    utils = importr('utils')\n",
    "    utils.chooseCRANmirror(ind=1)\n",
    "    # install sctransform\n",
    "    utils.install_packages(ro.vectors.StrVector(['sctransform']))\n",
    "\n",
    "# import sctransform and R Matrix package\n",
    "sctransform = importr('sctransform')\n",
    "rmatrix = importr('Matrix')\n",
    "\n",
    "# check sctransform version (should be 0.4.1)\n",
    "print(f'Installed sctransform version: {sctransform.__version__}')\n",
    "if not sctransform.__version__ == '0.4.1':\n",
    "    raise Exception('Please ensure that the installed sctransform is version 0.4.1')\n",
    "    \n",
    "# check that glmGamPoi depencency is installed\n",
    "if not ro.packages.isinstalled('glmGamPoi'):\n",
    "    raise Exception('Please install glmGamPoi: https://github.com/const-ae/glmGamPoi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3bee8",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "In this step you will enter the variables necessary to:\n",
    "1. Locate your input data\n",
    "1. Configure your data tensor (i.e. which three variables correspond to the three different modes or axes)\n",
    "1. Configure your normalization scheme\n",
    "\n",
    "When it comes to normalization, there are several parameters you need to define:\n",
    "- You will normalize by one of the variables that corresponds to a mode in your data tensor. You can think of this as the variable that defines the \"within\" groups. For example if I am normalizing by taxa, then the normalization procedure will be applied independently within each taxon in the dataset. Put another way, you can think of each taxon as a slab of your data tensor (i.e. a matrix), and the normalization will be applied independently to each slab.\n",
    "- For each slab, you will define which of the remaining two modes best corresponds to samples, and which to genes. For example, in metatranscriptomic data annotated with KEGG orthologies, the sample ID would be the sample mode, and the KEGG ID would be the gene mode. Additionally, if you want to account for batch effects in your data, the batch variable should relate to your sample mode.\n",
    "- You will define two thresholds that will apply to each slab (e.g. taxon):\n",
    "    1. Sample threshold: each gene must be detected in at least this many samples. Genes that fall below the threshold will be removed. Default is 3.\n",
    "    1. Detection threshold: each sample must contain non-zero values for at least this proportion of genes. Samples that fall below the threshold will be removed. Default is 0.01 (1%).\n",
    "    - Note that data removed due to thresholding is preserved, saved, and displayed at the end of this notebook so it can be used for troubleshooting or to refine the thresholds and normalization work flow.\n",
    "- If you want the normalization model to correct for batch effects, you will need to prepare a second csv file with columns corresponding to the sample mode in your data (including both sample ID and replicate), and with an additional column indicating the batch ID. For example, you might have a csv with the following headers: `['sample_id', 'replicate', 'batch_id']`. This file should include each unique combination of sample ID and replicate in your dataset, and the batch membership of each sample replicate should be indicated in the batch ID column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa2a772",
   "metadata": {},
   "source": [
    "Either store inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3873423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = ''  # Enter the filepath of your input data file:\n",
    "mode0 = ''  # Enter the column name that will correspond to the first mode of your tensor:\n",
    "mode1 = ''  # Enter the column name that will correspond to the second mode of your tensor:\n",
    "mode2 = ''  # Enter the column name that will correspond to the third mode of your tensor:\n",
    "rep = ''  # ('Enter the column name that corresponds to replicate IDs:')\n",
    "data = ''  # ('Enter the column name that corresponds to your data:')\n",
    "outdir = ''  # ('Enter the filepath of the output directory where you want files saved:')\n",
    "\n",
    "# check output directory exists\n",
    "if outdir:\n",
    "    if not os.path.isdir(outdir):\n",
    "        raise Exception(f'Unable to find the directory \"{outdir}\"')\n",
    "    else:\n",
    "        # make normalization directory within output directory\n",
    "        outdir = f'{outdir}/normalization'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "\n",
    "# check data file exists\n",
    "if datapath and not os.path.isfile(datapath):\n",
    "    raise Exception(f'Unable to find the file \"{datapath}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186fbf8",
   "metadata": {},
   "source": [
    "Or input using prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58228a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "\n",
    "# data file\n",
    "datapath = datapath or input('Enter the filepath of your input data file:')\n",
    "# check data file exists\n",
    "if not os.path.isfile(datapath):\n",
    "    raise Exception(f'Unable to find the file \"{datapath}\"')\n",
    "\n",
    "# output directory\n",
    "outdir = outdir or input('Enter the filepath of the output directory where you want files saved:')\n",
    "# check output directory exists\n",
    "if not os.path.isdir(outdir):\n",
    "    raise Exception(f'Unable to find the directory \"{outdir}\"')\n",
    "# make normalization directory within output directory\n",
    "outdir = f'{outdir}/normalization'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# column names\n",
    "mode0 = mode0 or input('Enter the column name that will correspond to the first mode of your tensor:')\n",
    "mode1 = mode1 or input('Enter the column name that will correspond to the second mode of your tensor:')\n",
    "mode2 = mode2 or input('Enter the column name that will correspond to the third mode of your tensor:')\n",
    "rep = rep or input('Enter the column name that corresponds to replicate IDs:')\n",
    "data = data or input('Enter the column name that corresponds to your data:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069083fd",
   "metadata": {},
   "source": [
    "Inspect df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7668dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv\n",
    "df = pd.read_csv(datapath)\n",
    "\n",
    "# check column names match inputs\n",
    "for column in [mode0, mode1, mode2, rep, data]:\n",
    "    if column not in df.columns:\n",
    "        raise Exception(f'Column name \"{column}\" not found in headers of file {datapath}')\n",
    "\n",
    "# tidy up dataframe\n",
    "df = df[[mode0, mode1, mode2, rep, data]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5af7f",
   "metadata": {},
   "source": [
    "Either store parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99b76d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mode_ = 2  # USE INTEGER NOT STRING (f'Which mode do you want to normalize by? 1-{mode0} 2-{mode1} 3-{mode2} (enter 1/2/3):'))\n",
    "sample_mode_ = 3  # USE INTEGER NOT STRING (f'Which mode corresponds to your sample variable? 1-{mode0} 2-{mode1} 3-{mode2} (enter 1/2/3):'))\n",
    "sample_thold = 3 # USE INTEGER NOT STRING 'Each {gene_mode} must be detected in what minimum number of unique {sample_mode}s? (Default is 3):'))\n",
    "gene_thold = 0.01 # USE FLOAT NOT STRINGf'Each {sample_mode} must contain what minimum proportion of nonzero {gene_mode}s? (Default is 0.01):'))\n",
    "save_data_ = 'y'  # 'Would you like to save the data output for each normalization? (Enter Y/N):'\n",
    "save_plots_ = 'y'  # 'Would you like to save the diagnostic plots for each normalization? (Enter Y/N):\n",
    "correction_ = 'n'  # 'Would you like to correct for batch effects? (Enter Y/N):').lower()\n",
    "metadata_path = ''  # input('Enter the filepath of your batch metadata file:')\n",
    "batch_id = ''  # input('Enter the column name that corresponds to the batch ID:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8a915",
   "metadata": {},
   "source": [
    "Or input using prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b0263-a6b6-4492-afbc-2dd21216af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization set up \n",
    "\n",
    "# by mode\n",
    "while norm_mode_ not in [1, 2, 3]:\n",
    "    norm_mode_ = int(input(f'Which mode do you want to normalize by? 1-{mode0} 2-{mode1} 3-{mode2} (enter 1/2/3):'))\n",
    "\n",
    "# sample mode\n",
    "while sample_mode_ not in [1, 2, 3]:\n",
    "    sample_mode_ = int(input(f'Which mode corresponds to your sample variable? 1-{mode0} 2-{mode1} 3-{mode2} (enter 1/2/3):'))\n",
    "# make a unique identifier that combines sampleID and replicateID\n",
    "norm_mode = [mode0, mode1, mode2][norm_mode_-1]\n",
    "sample_mode = [mode0, mode1, mode2][sample_mode_-1]\n",
    "df['sample_rep_id'] = df[sample_mode].astype(str) + df[rep].astype(str)\n",
    "gene_mode = [m for m in [mode0, mode1, mode2] if m not in [norm_mode, sample_mode]][0]\n",
    "\n",
    "# gene mode\n",
    "# thresholds\n",
    "sample_thold = sample_thold or int(input(f'Each {gene_mode} must be detected in what minimum number of unique {sample_mode}s? (Default is 3):'))\n",
    "gene_thold = gene_thold or float(input(f'Each {sample_mode} must contain what minimum proportion of nonzero {gene_mode}s? (Default is 0.01):'))\n",
    "\n",
    "# output options\n",
    "while save_data_ not in ['y', 'n']:\n",
    "    save_data_ = input('Would you like to save the data output for each normalization? (Enter Y/N):').lower()\n",
    "while save_plots_ not in ['y', 'n']:\n",
    "    save_plots_ = input('Would you like to save the diagnostic plots for each normalization? (Enter Y/N):').lower()\n",
    "# batch effects\n",
    "while correction_ not in ['y', 'n']:\n",
    "    correction_ = input('Would you like to correct for batch effects? (Enter Y/N):').lower()\n",
    "\n",
    "save_data = (save_data_ == 'y')\n",
    "save_plots = (save_plots_ == 'y')\n",
    "correction = (correction_ == 'y')\n",
    "\n",
    "if correction:\n",
    "    metadata_path = metadata_path or input('Enter the filepath of your batch metadata file:')\n",
    "    batch_id = batch_id or input('Enter the column name that corresponds to the batch ID:')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015a5bf",
   "metadata": {},
   "source": [
    "Set up params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05ddd10b-38d1-45f7-a4f4-b3250158473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if correction:\n",
    "    # check data file exists\n",
    "    if not os.path.isfile(metadata_path):\n",
    "        raise Exception(f'Unable to find the file \"{metadata_path}\"')\n",
    "    # read in metadata file\n",
    "    meta_df = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # check for sample, replicate, and batch columns\n",
    "    if sample_mode not in meta_df.columns:\n",
    "        raise Exception(f'Column name \"{sample_mode}\" not found in headers of file {metadata_path}. Columns found: {meta_df.columns}')\n",
    "    if rep not in meta_df.columns:\n",
    "        raise Exception(f'Column name \"{rep}\" not found in headers of file {metadata_path}. Columns found: {meta_df.columns}')\n",
    "    if not (meta_df[[sample_mode, rep]].drop_duplicates().reset_index(drop=True) == \\\n",
    "            df[[sample_mode, rep]].drop_duplicates().reset_index(drop=True)).all().all():\n",
    "        raise Exception(f'Files {datapath} and {metadata_path} have different values for columns {sample_mode} and {rep}.')  \n",
    "    if batch_id not in meta_df.columns:\n",
    "        raise Exception(f'Column name \"{batch_id}\" not found in headers of file {metadata_path}. Columns found: {meta_df.columns}')\n",
    "\n",
    "    # clean up metadata dataframe\n",
    "    meta_df['sample_rep_id'] = meta_df[sample_mode].astype(str) + '_' + meta_df[rep].astype(str)\n",
    "    meta_df = meta_df[['sample_rep_id', sample_mode, rep, batch_id]]\n",
    "    display(meta_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d45800",
   "metadata": {},
   "source": [
    "### Run sctransform on each slab of data\n",
    "\n",
    "In this step you'll run the sctransform model on your data. If you selected it in the first step, the data and/or plots resulting from each normalization run will be saved to the designated output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3f66e8d-10c8-4337-8bea-bd152caf5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for running normalization model\n",
    "\n",
    "# function to threshold sparsity of pandas dataframes\n",
    "def sparsity_thold_df(df, thold, axis=0):\n",
    "    \"\"\"Apply a sparsity threshold to a pandas.DataFrame so that only columns or rows with \n",
    "    greater than or equal to the threshold amount of nonzero values are retained.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe object.\n",
    "    thold : {int, float}\n",
    "        Threshold. If parameter is an int, then retained vectors must contain at least that number of \n",
    "        nonzero values. If parameter is a float, then at least this proportion of the vector must be nonzero.\n",
    "    axis : int\n",
    "        Axis to which threshold is applied. \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        Thresholded dataframe.\n",
    "    dropped_data_df : pandas.DataFrame\n",
    "        Data removed from the input dataframe as a result of the threshold\n",
    "    \"\"\"\n",
    "    if type(thold) is float:\n",
    "        thold = math.ceil(df.shape[axis] * thold)\n",
    "    elif type(thold) is not int:\n",
    "        raise Exception('Parameter `thold` must be either an int or float type value.')\n",
    "    mask = (df != 0).sum(axis).ge(thold)\n",
    "    if axis == 0:\n",
    "        output_df = df.loc[:, mask]\n",
    "        dropped_df = df.loc[:, ~mask]\n",
    "    elif axis == 1:\n",
    "        output_df = df.loc[mask, :]\n",
    "        dropped_df = df.loc[~mask, :]\n",
    "    else:\n",
    "        raise Exception('Invalid value for `axis` parameter.')\n",
    "    return output_df, dropped_df\n",
    "\n",
    "\n",
    "# function to calculate 0-sensitive geometric mean\n",
    "def geometric_mean(vector, pseudocount=1):\n",
    "    return np.exp(np.mean(np.log(vector + pseudocount))) - pseudocount\n",
    "\n",
    "\n",
    "# function to convert pandas dataframe to r matrix\n",
    "def pandas_dataframe_to_r_matrix(df, dtype=float):\n",
    "    \"\"\"\n",
    "    Function to convert pandas DataFrame objects to R matrix objects.\n",
    "    \"\"\"\n",
    "    if dtype is float:\n",
    "        vector = ro.vectors.FloatVector(df.values.flatten().tolist())\n",
    "    elif dtype is str:\n",
    "        vector = ro.vectors.StrVector(df.values.flatten().tolist())\n",
    "    elif dtype is int:\n",
    "        vector = ro.vectors.FloatVector(df.values.flatten().tolist())\n",
    "    else:\n",
    "        raise ValueError('The dtype {} is not recognized'.format(dtype))\n",
    "    matrix = rmatrix.Matrix(\n",
    "        data=vector, \n",
    "        nrow=df.shape[0], \n",
    "        ncol=df.shape[1], \n",
    "        byrow=True, \n",
    "        dimnames=[df.index.to_list(), df.columns.to_list()], \n",
    "        sparse=True\n",
    "    )\n",
    "    return matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d991bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the model on each slab\n",
    "\n",
    "# make normalization directory within output directory\n",
    "outdir = f'{outdir}/normalization'\n",
    "os.makedirs(outdir)\n",
    "\n",
    "# initialize residuals dataframe\n",
    "residuals_df = pd.DataFrame()\n",
    "\n",
    "# keep track of filtered data\n",
    "dropped_data_df = pd.DataFrame()\n",
    "\n",
    "# iterate through slabs\n",
    "slab_ids = df[norm_mode].unique()\n",
    "for i, slab_id in enumerate(slab_ids):\n",
    "    # separate out data\n",
    "    slab_df = df[df[norm_mode].eq(slab_id)].pivot(index=gene_mode, columns=['sample_rep_id'], values=data).fillna(0)\n",
    "    # apply sample threshold to filter out low-prevalence genes\n",
    "    slab_df, drop_df = sparsity_thold_df(slab_df, sample_thold, axis=1)\n",
    "    drop_df = drop_df.melt(value_name=data, ignore_index=False).reset_index()\n",
    "    drop_df[norm_mode] = slab_id\n",
    "    drop_df['drop_reason'] = f'{gene_mode} detected in fewer than {sample_thold} {sample_mode}s'\n",
    "    dropped_data_df = pd.concat([dropped_data_df, drop_df])\n",
    "    # apply gene threshold to filter out samples with low detection\n",
    "    slab_df, drop_df = sparsity_thold_df(slab_df, gene_thold, axis=0)\n",
    "    drop_df = drop_df.melt(value_name=data, ignore_index=False).reset_index()\n",
    "    drop_df[norm_mode] = slab_id\n",
    "    drop_df['drop_reason'] = f'{sample_mode} contains fewer than {math.ceil(slab_df.shape[0] * gene_thold)} nonzero {gene_mode}s'\n",
    "    dropped_data_df = pd.concat([dropped_data_df, drop_df])\n",
    "    # check for very small slabs\n",
    "    if (slab_df.shape[0] < 10) or (slab_df.shape[1] < sample_thold):\n",
    "        print(f'Skipping slab {i+1} of {len(slab_ids)}: {slab_id} ({slab_df.shape[1]} samples, {slab_df.shape[0]} genes)', flush=True)\n",
    "        print('\\tLimited nonzero data in this slab undermines the reliability of normalization with sctransform.', flush=True)\n",
    "        drop_df = slab_df.melt(value_name=data, ignore_index=False).reset_index()\n",
    "        drop_df[norm_mode] = slab_id\n",
    "        drop_df['drop_reason'] = f'{norm_mode} encompassed fewer than 10 {gene_mode}s or fewer than {sample_thold} {sample_mode}s'\n",
    "        dropped_data_df = pd.concat([dropped_data_df, drop_df])\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Normalizing slab {i+1} of {len(slab_ids)}: {slab_id} ({slab_df.shape[1]} samples, {slab_df.shape[0]} genes)', flush=True)\n",
    "\n",
    "    # make r version of slab dataframe\n",
    "    r_slab_df = pandas_dataframe_to_r_matrix(slab_df)\n",
    "    # pull out batch information\n",
    "    if correction:\n",
    "        sample_attr_df = meta_df.set_index('sample_rep_id').loc[slab_df.columns, [sample_mode, rep, batch_id]]\n",
    "    else: \n",
    "        sample_attr_df = df[['sample_rep_id', sample_mode, rep]].set_index('sample_rep_id').drop_duplicates()\n",
    "    r_sample_attr_df = pandas2ri.py2rpy(sample_attr_df)\n",
    "        \n",
    "\n",
    "    # fit vst normalization model\n",
    "    # Use glmgampoi\n",
    "    result = sctransform.vst(\n",
    "        r_slab_df, \n",
    "        cell_attr=r_sample_attr_df, \n",
    "        batch_var=(ro.vectors.StrVector([batch_id]) if correction else ro.NULL),\n",
    "        min_cells=sample_thold,\n",
    "        return_gene_attr=True, \n",
    "        return_cell_attr=True, \n",
    "        vst_flavor='v2', \n",
    "        verbosity=2,\n",
    "        method='glmGamPoi'\n",
    "    )\n",
    "\n",
    "    # Get names from result in case genes get dropped from sctransform (not overdispersed)\n",
    "    with ro.conversion.localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        genes = ro.conversion.rpy2py(result[11]).index.values\n",
    "        cells = ro.conversion.rpy2py(result[10]).index.values\n",
    "    # convert residuals result to a dataframe\n",
    "    result_df = pd.DataFrame(\n",
    "        np.asarray(result[0]), \n",
    "        index=genes, \n",
    "        columns=cells\n",
    "    )\n",
    "\n",
    "    # prepare to save requested outputs\n",
    "    if save_data or save_plots:\n",
    "        # make unique output directory per slab\n",
    "        dir_path = f'{outdir}/{slab_id}'\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        # calculate residuals\n",
    "        residual_var = result_df.var(axis=1)\n",
    "\n",
    "    # save data if requested\n",
    "    if save_data:\n",
    "        # save csv of residuals\n",
    "        result_df.to_csv(f'{dir_path}/residuals_{slab_id}.csv')\n",
    "        # save csv of residual variances\n",
    "        res_var_df = residual_var.reset_index().rename(columns={0:'residual_variance'})\n",
    "        res_var_df = res_var_df.sort_values('residual_variance', ascending=False).reset_index()\n",
    "        res_var_df.to_csv(f'{dir_path}/residual_variances_{slab_id}.csv')\n",
    "\n",
    "    # save plots if requested\n",
    "    if save_plots:\n",
    "        # plots of model parameters\n",
    "        plots = sctransform.plot_model_pars(result, show_theta=True)\n",
    "        img = image_png(plots)\n",
    "        with open(f'{dir_path}/parameters_{slab_id}.png', 'wb') as png:\n",
    "            png.write(img.data)\n",
    "        # plot of high variance genes\n",
    "        means = slab_df.apply(geometric_mean, axis=1)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.scatterplot(x=means, y=residual_var, alpha=0.1);\n",
    "        plt.xlabel(f'geometric mean of {gene_mode} {data}')\n",
    "        plt.xscale('log')\n",
    "        plt.ylabel('residual variance')\n",
    "        plt.title(f'normalized residual variance\\nvs. mean {gene_mode} {data} ({slab_id})')\n",
    "        plt.savefig(f'{dir_path}/residual_variances_{slab_id}.png')\n",
    "        plt.show()\n",
    "\n",
    "    # concatenate result with other residuals\n",
    "    result_df = result_df.melt(value_name='residual', ignore_index=False).reset_index()\n",
    "    result_df[norm_mode] = slab_id\n",
    "    residuals_df = pd.concat([residuals_df, result_df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723dcff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda05f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df_ = residuals_df.rename(columns={'variable': 'sample_rep_id', 'index': gene_mode})\n",
    "residuals_df_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fde11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normalized data as a csv\n",
    "\n",
    "# revert column names changed by sctransform\n",
    "residuals_df = residuals_df.rename(columns={'variable': 'sample_rep_id', 'index': gene_mode})\n",
    "\n",
    "# add back sample information\n",
    "residuals_df = pd.merge(residuals_df, df[['sample_rep_id', sample_mode, rep]].drop_duplicates(), on='sample_rep_id', how='left')\n",
    "\n",
    "# add in raw count data\n",
    "residuals_df = pd.merge(residuals_df, df, on=['sample_rep_id', mode0, mode1, mode2, rep], how='left').fillna(0)\n",
    "\n",
    "# tidy up dataframe\n",
    "residuals_df = residuals_df[[mode0, mode1, mode2, rep, data, 'residual']]\n",
    "\n",
    "# save output\n",
    "residuals_df.to_csv(f'{outdir}/normalized-residuals.csv')\n",
    "\n",
    "residuals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012df29b-3d4d-410e-a2c6-ec802400b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine data that was removed during normalization process\n",
    "\n",
    "# remove zero values\n",
    "dropped_data_df = dropped_data_df[dropped_data_df[data] != 0.0]\n",
    "\n",
    "# add back sample information\n",
    "dropped_data_df = pd.merge(dropped_data_df, df[['sample_rep_id', sample_mode, rep]].drop_duplicates(), on='sample_rep_id', how='left')\n",
    "\n",
    "# tidy up dataframe\n",
    "dropped_data_df = dropped_data_df[[mode0, mode1, mode2, rep, data, 'drop_reason']]\n",
    "\n",
    "# show some summary statistics\n",
    "for variable in ['drop_reason', mode0, mode1, mode2]:\n",
    "    print(dropped_data_df[variable].value_counts())\n",
    "\n",
    "# save drop data\n",
    "dropped_data_df.to_csv(f'{outdir}/removed-data.csv')      \n",
    "\n",
    "dropped_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06d6d9-9513-4a6c-be82-0ec7626028ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
