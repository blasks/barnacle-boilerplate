{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Analyze final Barnacle model\n",
    "\n",
    "Use this notebook to compile and analyze the final version of your Barnacle model. This should be the version of the model that is fit with the optimal parameters you identified in step 4. This compilation and analysis includes several parts:\n",
    "1. Align the components between bootstraps of your final model.\n",
    "    - The order of components is not fixed in this tensor decomposition model. Therefore, in order to compare between bootstraps, the components must first be aligned to one another.\n",
    "    - The aligned bootstraps will be saved as an xarray.DataSet so that you can access them for further analysis\n",
    "1. Extract the model weights for each component.\n",
    "    - Each component can be understood to model a different pattern in the data. Depending on how you set up your data and your Barnacle model, each pattern might also be associated with a different cluster (e.g. gene clusters). This step separates out each component so you can more closely examine the pattern and/or cluster each is modeling.\n",
    "1. Visualize your model.\n",
    "    - Effective visualization depends on your data type, size, dimensions, and the questions you are asking. A few potential visualizations are suggested below to help get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorly as tl\n",
    "import tlviz\n",
    "import xarray as xr\n",
    "\n",
    "from barnacle.tensors import SparseCPTensor\n",
    "from barnacle.utils import subset_cp_tensor\n",
    "from functools import reduce\n",
    "from tlab.cp_tensor import load_cp_tensor\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Align model bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUTS -- edit these variables as needed\n",
    "\n",
    "# path to directory where all of the models from your parameter search were saved (e.g. 'directory/fitting/'\n",
    "modelpath = 'data/fitting'\n",
    "\n",
    "# output directory where produced files will be saved (e.g. 'data/'\n",
    "outdir = 'data'\n",
    "\n",
    "# optimal rank parameter (number of components) used to fit your final model\n",
    "optimal_rank = 5\n",
    "\n",
    "# optimal lambda parameter (sparsity coefficient) used to fit your final model\n",
    "optimal_lambda = 1.0\n",
    "\n",
    "# number of bootstraps used for final model\n",
    "n_bootstraps = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b053723d8bdf4405b522202533d3262a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting sample names:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200dc2ec71ab4315b2a3b81dbec3250b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing model bootstraps:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 100 model bootstraps, each with 3 replicates.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012f4c9c174a41ed9386b5325f06c4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Identifying best reference model from bootstraps:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bootstraps will be aligned to the following reference model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_bootstrap</th>\n",
       "      <th>reference_replicate</th>\n",
       "      <th>mean_fms</th>\n",
       "      <th>median_fms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>C</td>\n",
       "      <td>0.645633</td>\n",
       "      <td>0.661761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reference_bootstrap reference_replicate  mean_fms median_fms\n",
       "0                  97                   C  0.645633   0.661761"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model bootstraps successfully aligned.\n"
     ]
    }
   ],
   "source": [
    "# align bootstraps of final model\n",
    "\n",
    "# set up parameters and data structures\n",
    "example_ds = xr.load_dataset(f\"{modelpath}/bootstrap0/dataset-bootstrap0.nc\")\n",
    "replicates = [str(l) for l in set(example_ds.replicate_id.data)]\n",
    "bootstraps = np.arange(n_bootstraps)\n",
    "samplenames = {rep: [] for rep in replicates}    # sample names\n",
    "cps = {rep: [] for rep in replicates}   # cp tensors with all samples present\n",
    "subset_cps = {rep: [] for rep in replicates}    # cp tensors subset to just common samples\n",
    "\n",
    "# collect sample names of each bootstrap/replicate pair\n",
    "for boot in tqdm(bootstraps, desc='Extracting sample names'):\n",
    "    for rep in replicates:\n",
    "        ds = xr.open_dataset(f\"{modelpath}/bootstrap{boot}/replicate{rep}/shuffled-replicate-{rep}.nc\")\n",
    "        samplenames[rep].append(ds.sample_id.data)\n",
    "# compile set of samplenames common to all bootstrap / replicate splits\n",
    "samplenames['common'] = reduce(np.intersect1d, itertools.chain.from_iterable([samplenames[r] for r in replicates]))\n",
    "\n",
    "# import all fitted models\n",
    "for boot in tqdm(bootstraps, desc='Importing model bootstraps'):\n",
    "    for rep in replicates:\n",
    "        # put together data path\n",
    "        path_cp = f\"bootstrap{boot}/replicate{rep}/rank{optimal_rank}/lambda{optimal_lambda}/fitted-model.h5\"\n",
    "        # store normalized cp tensor to cps\n",
    "        cp = tl.cp_normalize(load_cp_tensor(f\"{modelpath}/{path_cp}\"))\n",
    "        cps[rep].append(cp)\n",
    "        # pull out common samplenames and store in subset_aligned_cps\n",
    "        idx = np.where(np.isin(samplenames[rep][boot], samplenames['common']))[0]\n",
    "        subset_cps[rep].append(subset_cp_tensor(cp, {2: idx}))\n",
    "print(f\"Successfully imported {len(cps[rep])} model bootstraps, each with {len(replicates)} replicates.\")\n",
    "\n",
    "# find best representative reference cp tensor\n",
    "results = []\n",
    "for ref_rep, ref_boot in tqdm(list(itertools.product(replicates, bootstraps)), desc='Identifying best reference model from bootstraps'):\n",
    "    reference_cp = subset_cps[ref_rep][ref_boot]\n",
    "    for comp_rep, comp_boot in list(itertools.product(replicates, bootstraps)):\n",
    "        # no point in comparing to self\n",
    "        if ref_rep == comp_rep and ref_boot == comp_boot:\n",
    "            continue\n",
    "        comparison_cp = subset_cps[comp_rep][comp_boot]\n",
    "        fms = tlviz.factor_tools.factor_match_score(\n",
    "            reference_cp, \n",
    "            comparison_cp, \n",
    "            consider_weights=False\n",
    "        )\n",
    "        results.append({\n",
    "            'reference_bootstrap': ref_boot, \n",
    "            'reference_replicate': ref_rep, \n",
    "            'comparison_bootstrap': comp_boot, \n",
    "            'comparison_replicate': comp_rep, \n",
    "            'fms': fms, \n",
    "        })\n",
    "# summarize overall mean fms  \n",
    "fms_df = pd.DataFrame(results)\n",
    "fms_summary_df = fms_df.groupby([\n",
    "    'reference_bootstrap', \n",
    "    'reference_replicate'\n",
    "]).agg(\n",
    "    mean_fms=('fms', 'mean'), \n",
    "    median_fms=('fms', 'median'), \n",
    ").reset_index()\n",
    "# find the best representative bootstrap model based on maximum mean FMS\n",
    "best_ref = fms_summary_df.iloc[fms_summary_df.mean_fms.idxmax(), :]\n",
    "print('All bootstraps will be aligned to the following reference model:')\n",
    "display(pd.DataFrame(best_ref).T.reset_index(drop=True))\n",
    "\n",
    "# permute reference cp so that components are in descending order of explaned variation\n",
    "ref_cp = tlviz.factor_tools.permute_cp_tensor(\n",
    "    subset_cps[best_ref['reference_replicate']][best_ref['reference_bootstrap']], \n",
    "    consider_weights=False\n",
    ")        \n",
    "\n",
    "# realign all the other cp tensors against the best representative cp tensor\n",
    "for rep in replicates:\n",
    "    for boot in bootstraps:\n",
    "        # permute components to line up with best representative reference cp\n",
    "        perm = tlviz.factor_tools.get_cp_permutation(subset_cps[rep][boot], reference_cp_tensor=ref_cp, consider_weights=False)\n",
    "        cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(cps[rep][boot], permutation=perm)\n",
    "        subset_cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(subset_cps[rep][boot], permutation=perm)\n",
    "print('All model bootstraps successfully aligned.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile aligned model weights into a single xarray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile aligned model weights into xarray.Datasets\n",
    "\n",
    "for cyano in ['pro', 'syn']:\n",
    "    # set up data structures\n",
    "    component_labels = np.arange(ranks[cyano]) + 1 # 1-based indexing for ease of communication\n",
    "    component_weights = []\n",
    "    ortholog_weights = []\n",
    "    taxon_weights = []\n",
    "    sample_df = pd.DataFrame()\n",
    "    for boot in bootstraps:\n",
    "        component_weights.append([])\n",
    "        ortholog_weights.append([])\n",
    "        taxon_weights.append([])\n",
    "        boot_sample_df = pd.DataFrame()\n",
    "        for rep in replicates:\n",
    "            # fetch shuffled tensor xr.DataSet\n",
    "            ds = xr.open_dataset(datapath / f'{cyano}/bootstrap{boot}/dataset-bootstrap{boot}.nc')\n",
    "            # fetch aligned cp tensor\n",
    "            cp = aligned_cps[cyano][rep][boot]\n",
    "            # add component weights to list\n",
    "            component_weights[boot].append(cp.weights)\n",
    "            # add gene weights to list\n",
    "            ortholog_weights[boot].append(cp.factors[0].T)\n",
    "            # add taxon weights to list\n",
    "            taxon_weights[boot].append(cp.factors[1].T)\n",
    "            # put sample weights into a pd.DataFrame\n",
    "            rep_sample_df = pd.DataFrame(\n",
    "                cp.factors[2], index=samplenames[cyano][rep][boot], columns=component_labels\n",
    "            ).reset_index().rename(columns={'index': 'SampleName'})\n",
    "            rep_sample_df['Replicate'] = rep\n",
    "            # concatenate sample weights of all replicates\n",
    "            if len(boot_sample_df) == 0:\n",
    "                boot_sample_df = rep_sample_df\n",
    "            else:\n",
    "                boot_sample_df = pd.concat([boot_sample_df, rep_sample_df])\n",
    "        # merge sample id from xr.DataSet into pd.DataFrame\n",
    "        boot_sample_df = pd.merge(\n",
    "            left=ds[['SampleName', 'Replicate']].to_pandas().reset_index(), \n",
    "            right=boot_sample_df, \n",
    "            on=['SampleName', 'Replicate'],how='left'\n",
    "        )\n",
    "        boot_sample_df['Bootstrap'] = boot\n",
    "        # concatenate sample weights of all bootstraps\n",
    "        if len(sample_df) == 0:\n",
    "            sample_df = boot_sample_df\n",
    "        else:\n",
    "            sample_df = pd.concat([sample_df, boot_sample_df])\n",
    "\n",
    "    # compile everything into an xarray.Dataset\n",
    "    ds = xr.Dataset(\n",
    "        dict(\n",
    "            ComponentWeight=xr.DataArray(\n",
    "                np.array(component_weights), \n",
    "                coords=[bootstraps, replicates, component_labels], \n",
    "                dims=['Bootstrap', 'Replicate', 'Component']\n",
    "            ),\n",
    "            GeneWeight=xr.DataArray(\n",
    "                np.array(ortholog_weights), \n",
    "                coords=[bootstraps, replicates, component_labels, ds.Ortholog.data], \n",
    "                dims=['Bootstrap', 'Replicate', 'Component', 'Ortholog']\n",
    "            ), \n",
    "            TaxonWeight=xr.DataArray(\n",
    "                np.array(taxon_weights), \n",
    "                coords=[bootstraps, replicates, component_labels, ds.Clade.data], \n",
    "                dims=['Bootstrap', 'Replicate', 'Component', 'Clade']\n",
    "            ), \n",
    "            SampleWeight=xr.DataArray.from_series(\n",
    "                sample_df.melt(\n",
    "                    id_vars=['Bootstrap', 'Replicate', 'SampleName'], \n",
    "                    value_vars=component_labels, \n",
    "                    var_name='Component', \n",
    "                    value_name='Weight'\n",
    "                ).set_index(['Bootstrap', 'Replicate', 'Component', 'SampleName'])['Weight']\n",
    "            ), \n",
    "            Sample=xr.DataArray.from_series(\n",
    "                sample_df.set_index(['Bootstrap', 'Replicate', 'SampleName'])['Sample']\n",
    "            ), \n",
    "            Annotation={'pro': pro_ds, 'syn': syn_ds}[cyano].Annotation\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add reference tensor and sparsity coefficient as an attribute\n",
    "    stats = best_rep_df.loc[best_rep_df.genus == cyano, :].to_dict(orient='records')[0]\n",
    "    ds.attrs['Rank'] = ranks[cyano]\n",
    "    ds.attrs['Lambda'] = lambdas[cyano]\n",
    "    ds.attrs['AlignRefBootstrap'] = stats['reference_bootstrap']\n",
    "    ds.attrs['AlignRefReplicate'] = stats['reference_replicate']\n",
    "    \n",
    "    # save Dataset as netCDF4 file\n",
    "    ds.to_netcdf(outdir / f'{cyano}-aligned-models.nc')\n",
    "    \n",
    "    # assign each dataset to its own variable\n",
    "    if cyano == 'pro':\n",
    "        pro_ds = ds\n",
    "    elif cyano == 'syn':\n",
    "        syn_ds = ds\n",
    "\n",
    "# examine Pro Dataset\n",
    "pro_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine Syn Dataset\n",
    "\n",
    "syn_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
