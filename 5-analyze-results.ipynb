{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Analyze final Barnacle model\n",
    "\n",
    "Use this notebook to compile and analyze the final version of your Barnacle model. This should be the version of the model that is fit with the optimal parameters you identified in step 4. There are several parts of this compilation and analysis notebook:\n",
    "1. Align the components between bootstraps of your final model.\n",
    "    - The order of components is not fixed in this tensor decomposition model. Therefore, in order to compare between bootstraps, the components must first be aligned to one another.\n",
    "    - The aligned bootstraps will be saved as an xarray.DataSet so that you can access them for further analysis\n",
    "1. Summarize the model weights for each component.\n",
    "    - Each component can be understood to model a different pattern in the data. Depending on how you set up your data and your Barnacle model, each pattern might also be associated with a different cluster (e.g. gene clusters). This step separates out each component so you can more closely examine the pattern and/or cluster each is modeling.\n",
    "1. Visualize your model.\n",
    "    - Effective visualization depends on your data type, size, dimensions, and the questions you are asking. A few potential visualizations are suggested below to help get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorly as tl\n",
    "import tlviz\n",
    "import xarray as xr\n",
    "\n",
    "from barnacle.tensors import SparseCPTensor\n",
    "from barnacle.utils import subset_cp_tensor\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "from tlab.cp_tensor import load_cp_tensor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# set color palette\n",
    "sns.set_palette(sns.color_palette([\n",
    "    '#9B5DE5', '#FFAC69', '#00C9AE', '#FD3F92', '#0F0A0A', '#959AB1', '#FFDB66', '#FFB1CA', '#63B9FF', '#4F1DD7'\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Align model bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUTS -- edit these variables as needed\n",
    "\n",
    "# path to directory where the outputs from your parameter search were saved (e.g. 'directory/barnacle/fitting/')\n",
    "fitpath = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/G3NS/sub_taxa_02/barnacle/fitting'\n",
    "\n",
    "# path to the normalized data tensor used to fit barnacle (e.g. 'directory/data-tensor.nc')\n",
    "datapath = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/G3NS/sub_taxa_02/data-tensor.nc'\n",
    "\n",
    "# optimal rank parameter (number of components) used to fit your final model\n",
    "optimal_rank = 4\n",
    "\n",
    "# optimal lambda parameter (sparsity coefficient) used to fit your final model\n",
    "optimal_lambda = 3.2\n",
    "\n",
    "# number of bootstraps used for final model\n",
    "n_bootstraps = 10\n",
    "\n",
    "# output directory where files produced by this notebook will be saved\n",
    "outdir = fitpath.strip('fitting') + 'model'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.makedirs(outdir)\n",
    "print(f\"File outputs of this notebook will be saved here: {outdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align bootstraps of final model\n",
    "\n",
    "# set up parameters and data structures\n",
    "input_ds = xr.load_dataset(f\"{fitpath}/bootstrap0/dataset-bootstrap0.nc\")\n",
    "replicates = [str(l) for l in set(input_ds.replicate_id.data)]\n",
    "bootstraps = np.arange(n_bootstraps)\n",
    "samplenames = {rep: [] for rep in replicates}    # sample names\n",
    "cps = {rep: [] for rep in replicates}   # cp tensors with all samples present\n",
    "subset_cps = {rep: [] for rep in replicates}    # cp tensors subset to just common samples\n",
    "\n",
    "# collect sample names of each bootstrap/replicate pair\n",
    "for boot in tqdm(bootstraps, desc='Extracting sample names'):\n",
    "    for rep in replicates:\n",
    "        ds = xr.open_dataset(f\"{fitpath}/bootstrap{boot}/replicate{rep}/shuffled-replicate-{rep}.nc\")\n",
    "        samplenames[rep].append(ds.sample_id.data)\n",
    "# compile set of samplenames common to all bootstrap / replicate splits\n",
    "samplenames['common'] = reduce(np.intersect1d, itertools.chain.from_iterable([samplenames[r] for r in replicates]))\n",
    "\n",
    "# import all fitted models\n",
    "for boot in tqdm(bootstraps, desc='Importing model bootstraps'):\n",
    "    for rep in replicates:\n",
    "        # put together data path\n",
    "        path_cp = f\"bootstrap{boot}/replicate{rep}/rank{optimal_rank}/lambda{optimal_lambda}/fitted-model.h5\"\n",
    "        # store normalized cp tensor to cps\n",
    "        cp = tl.cp_normalize(load_cp_tensor(f\"{fitpath}/{path_cp}\"))\n",
    "        cps[rep].append(cp)\n",
    "        # pull out common samplenames and store in subset_aligned_cps\n",
    "        idx = np.where(np.isin(samplenames[rep][boot], samplenames['common']))[0]\n",
    "        subset_cps[rep].append(subset_cp_tensor(cp, {2: idx}))\n",
    "print(f\"Successfully imported {len(cps[rep])} model bootstraps, each with {len(replicates)} replicates.\")\n",
    "\n",
    "# find best representative reference cp tensor\n",
    "results = []\n",
    "combos = list(itertools.product(replicates, bootstraps))\n",
    "for ref_rep, ref_boot in tqdm(combos, desc='Identifying best reference model from bootstraps'):\n",
    "    # limit comparisons to a random sample of 100 bootstraps\n",
    "    if len(combos) > 100:\n",
    "        combos = [combos[i] for i in np.random.choice(len(combos), size=100, replace=False)]\n",
    "    for comp_rep, comp_boot in combos:\n",
    "        # no point in comparing to self\n",
    "        if ref_rep == comp_rep and ref_boot == comp_boot:\n",
    "            continue\n",
    "        reference_cp = subset_cps[ref_rep][ref_boot]\n",
    "        comparison_cp = subset_cps[comp_rep][comp_boot]\n",
    "        fms = tlviz.factor_tools.factor_match_score(reference_cp, comparison_cp, consider_weights=False)\n",
    "        results.append({\n",
    "            'reference_bootstrap': ref_boot, \n",
    "            'reference_replicate': ref_rep, \n",
    "            'comparison_bootstrap': comp_boot, \n",
    "            'comparison_replicate': comp_rep, \n",
    "            'fms': fms, \n",
    "        })\n",
    "# summarize overall mean fms  \n",
    "fms_df = pd.DataFrame(results)\n",
    "fms_summary_df = fms_df.groupby([\n",
    "    'reference_bootstrap', \n",
    "    'reference_replicate'\n",
    "]).agg(\n",
    "    mean_fms=('fms', 'mean'), \n",
    "    median_fms=('fms', 'median'), \n",
    ").reset_index()\n",
    "# find the best representative bootstrap model based on maximum mean FMS\n",
    "best_ref = fms_summary_df.iloc[fms_summary_df.mean_fms.idxmax(), :]\n",
    "print('All bootstraps will be aligned to the following reference model:')\n",
    "display(pd.DataFrame(best_ref).T.reset_index(drop=True))\n",
    "\n",
    "# permute reference cp so that components are in descending order of explaned variation\n",
    "ref_cp = tlviz.factor_tools.permute_cp_tensor(\n",
    "    subset_cps[best_ref['reference_replicate']][best_ref['reference_bootstrap']], \n",
    "    consider_weights=False\n",
    ")        \n",
    "\n",
    "# realign all the other cp tensors against the best representative cp tensor\n",
    "for rep in replicates:\n",
    "    for boot in bootstraps:\n",
    "        # permute components to line up with best representative reference cp\n",
    "        perm = tlviz.factor_tools.get_cp_permutation(subset_cps[rep][boot], reference_cp_tensor=ref_cp, consider_weights=False)\n",
    "        cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(cps[rep][boot], permutation=perm)\n",
    "        subset_cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(subset_cps[rep][boot], permutation=perm)\n",
    "print('All model bootstraps successfully aligned.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile aligned model weights into a single xarray.Dataset\n",
    "\n",
    "# set up data structures\n",
    "component_labels = np.arange(optimal_rank) + 1 # 1-based indexing for ease of communication\n",
    "weights = {'mode0': [], 'mode1': [], 'component': [], 'pct_var': []}\n",
    "sample_info_df = pd.merge(\n",
    "    input_ds.sample_id.to_series().reset_index(), \n",
    "    input_ds.replicate_id.to_series().reset_index(), \n",
    "    on='sample_replicate_id', how='inner'\n",
    ")[['sample_id', 'replicate_id']].rename(columns={'sample_id': 'sample', 'replicate_id': 'replicate'})\n",
    "sample_df = pd.DataFrame()\n",
    "\n",
    "# pull model weights from each bootstrap\n",
    "for boot in tqdm(bootstraps, desc='Compiling weights from each bootstrap'):\n",
    "    boot_sample_df = pd.DataFrame()\n",
    "    for key in weights.keys():\n",
    "        weights[key].append([])\n",
    "    for rep in replicates:\n",
    "        # fetch aligned cp tensor\n",
    "        cp = cps[rep][boot]\n",
    "        # add mode 0 weights to list\n",
    "        weights['mode0'][boot].append(cp.factors[0].T)\n",
    "        # add mode 1 weights to list\n",
    "        weights['mode1'][boot].append(cp.factors[1].T)\n",
    "        # add component weights to list\n",
    "        weights['component'][boot].append(cp.weights)\n",
    "        # calculate percent variation explained by components and add to list\n",
    "        weights['pct_var'][boot].append(tlviz.factor_tools.percentage_variation(cp, dataset=input_ds.data.data, method='data'))\n",
    "        # put mode 2 (sample) weights into a pd.DataFrame\n",
    "        rep_sample_df = pd.DataFrame(\n",
    "            cp.factors[2], index=samplenames[rep][boot], columns=component_labels\n",
    "        ).reset_index().rename(columns={'index': 'sample'})\n",
    "        rep_sample_df['replicate'] = rep\n",
    "        # concatenate sample weights of all replicates\n",
    "        boot_sample_df = pd.concat([boot_sample_df, rep_sample_df])\n",
    "    # merge sample info into sample weights dataframe\n",
    "    boot_sample_df = pd.merge(left=sample_info_df, right=boot_sample_df, on=['sample', 'replicate'], how='left')\n",
    "    boot_sample_df['bootstrap'] = boot\n",
    "    # concatenate sample weights of all bootstraps\n",
    "    sample_df = pd.concat([sample_df, boot_sample_df])\n",
    "\n",
    "# compile everything into an xarray.Dataset\n",
    "modes = list(input_ds.coords)\n",
    "modes[2] = 'sample'\n",
    "ds = xr.Dataset({\n",
    "    f\"{modes[0]}_weights\": xr.DataArray(\n",
    "        np.array(weights['mode0']), \n",
    "        coords=[bootstraps, replicates, component_labels, input_ds[modes[0]].data], \n",
    "        dims=['bootstrap', 'replicate', 'component', modes[0]]\n",
    "    ), \n",
    "    f\"{modes[1]}_weights\": xr.DataArray(\n",
    "        np.array(weights['mode1']), \n",
    "        coords=[bootstraps, replicates, component_labels, input_ds[modes[1]].data], \n",
    "        dims=['bootstrap', 'replicate', 'component', modes[1]]\n",
    "    ), \n",
    "    f\"{modes[2]}_weights\": xr.DataArray.from_series(\n",
    "        sample_df.melt(\n",
    "            id_vars=['bootstrap', 'replicate', modes[2]], \n",
    "            value_vars=component_labels, \n",
    "            var_name='component', \n",
    "            value_name='sample_weights'\n",
    "        ).set_index(['bootstrap', 'replicate', 'component', modes[2]])[f\"{modes[2]}_weights\"]\n",
    "    ), \n",
    "    'component_weights': xr.DataArray(\n",
    "            np.array(weights['component']), \n",
    "            coords=[bootstraps, replicates, component_labels], \n",
    "            dims=['bootstrap', 'replicate', 'component']\n",
    "    ),\n",
    "    'percent_variation': xr.DataArray(\n",
    "            np.array(weights['pct_var']), \n",
    "            coords=[bootstraps, replicates, component_labels], \n",
    "            dims=['bootstrap', 'replicate', 'component']\n",
    "    )\n",
    "})\n",
    "\n",
    "# add reference tensor, rank, and sparsity coefficient as attributes\n",
    "ds.attrs['rank'] = optimal_rank\n",
    "ds.attrs['lambda'] = optimal_lambda\n",
    "ds.attrs['n_bootstraps'] = n_bootstraps\n",
    "ds.attrs['align_ref_bootstrap'] = best_ref['reference_bootstrap']\n",
    "ds.attrs['align_ref_replicate'] = best_ref['reference_replicate']\n",
    "\n",
    "# save Dataset as netCDF4 file\n",
    "ds.to_netcdf(f\"{outdir}/aligned-bootstraps.nc\")\n",
    "\n",
    "# examine Dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Summarize model weights for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component=3\n",
    "mode='KO'\n",
    "df = pd.DataFrame({\n",
    "    'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "}).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model weights for each component, and save summaries as csv files\n",
    "\n",
    "# limit what is visualized\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "max_components = 5    # maximum number of components to show in this visualization\n",
    "\n",
    "# summarize weights across bootstraps and replicates\n",
    "mean_ds = ds.mean(dim=['bootstrap', 'replicate'])    # mean of weights\n",
    "std_ds = ds.std(dim=['bootstrap', 'replicate'])    # standard deviation of weights\n",
    "med_ds = ds.median(dim=['bootstrap', 'replicate'])    # median of weights\n",
    "support_ds = (ds != 0).mean(dim=['bootstrap', 'replicate']) * 100     # bootstrap support (percent of weights nonzero)\n",
    "\n",
    "# plot relative contribution of components\n",
    "fig, axis = plt.subplots(figsize=(min(15, len(ds.component.data)), 5))\n",
    "sns.boxplot(ds.percent_variation.to_series().reset_index(), x='component', y='percent_variation', ax=axis); \n",
    "axis.set(xlabel='Component', ylabel='% Variation Explained'); \n",
    "plt.show()\n",
    "\n",
    "# extract summary of weights for each component\n",
    "for component in ds.component.data:\n",
    "    print(f\"\\nComponent {component}:\\n\")\n",
    "    if not os.path.isdir(f\"{outdir}/component{component}\"):\n",
    "        os.makedirs(f\"{outdir}/component{component}\")\n",
    "    for i, mode in enumerate(modes):\n",
    "        # make dataframe summarizing weights\n",
    "        df = pd.DataFrame({\n",
    "            'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        }).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "        # drop values with a median weight of zero (equivalent to 50% bootstrap support threshold)\n",
    "        # df = df[~df.median_weight.eq(0)].reset_index()\n",
    "        df = df[~df.mean_weight.eq(0)].reset_index()\n",
    "        # save data\n",
    "        df.to_csv(f\"{outdir}/component{component}/{mode}_weights_summary.csv\", index=False)\n",
    "        # plot top weights\n",
    "        if component <= max_components:\n",
    "            df = df.head(max_elements) # just look at top weights\n",
    "            df[mode] = df[mode].astype(str) # in case labels aren't strings\n",
    "            print(df[mode].values.tolist())\n",
    "            fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "            sns.barplot(df, x=mode, y='mean_weight', color=sns.color_palette()[i+1], legend=False, ax=axis); \n",
    "            axis.errorbar(x=df[mode], y=df['mean_weight'], yerr=df['std_weight'], fmt='none', color=sns.color_palette()[5])\n",
    "            axis.set(title=f\"Component {component} Top {mode.capitalize()} Weights\", xlabel=None, ylabel='Weight'); \n",
    "            fig.autofmt_xdate(rotation=90)\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare weight profiles between components\n",
    "\n",
    "# make dataframe for concatenating weight profiles\n",
    "concat_profile_df = pd.DataFrame()\n",
    "\n",
    "# iterate through comparisons\n",
    "comparisons = modes + ['concatenated']\n",
    "for mode in comparisons:\n",
    "    print(f\"Comparing {mode} weights:\")\n",
    "    if mode != 'concatenated':\n",
    "        # calculate median weight profile for each component in model\n",
    "        profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "        # add mode weight profile to concatenated profile\n",
    "        concat_profile_df = pd.concat([concat_profile_df, profile_df], axis=1)\n",
    "    else:\n",
    "        profile_df = concat_profile_df\n",
    "    # calculate correlation matrix\n",
    "    corr_df = profile_df.T.corr()\n",
    "    # make clustered heatmap\n",
    "    g = sns.clustermap(\n",
    "        corr_df.fillna(0), mask=corr_df.isna(), cmap='PuOr_r', vmin=-1, vmax=1, cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "        xticklabels=True, yticklabels=True\n",
    "    )\n",
    "    g.fig.suptitle(f\"Similarity of {mode.capitalize()} Weights Between Components\", y=1.02); \n",
    "    plt.show(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 0) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[0]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n",
    "\n",
    "\n",
    "df[mode].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 1) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[1]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n",
    "\n",
    "df[mode].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 2 -- sample mode) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[2]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined figure that looks at top weights across all three modes for a subset of components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 10    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "combined_df = pd.DataFrame()\n",
    "for mode in modes[:3]:\n",
    "    if heuristic == 'max_weight':\n",
    "        # weights sorted by maximum across all components\n",
    "        idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "    elif heuristic == 'max_variation': \n",
    "        idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "    df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "    df = df.rename(columns={mode: 'Label', f\"{mode}_weights\": 'Weights'})\n",
    "    df['mode'] = mode\n",
    "    combined_df = pd.concat([combined_df, df], axis=0)\n",
    "# pull out just components of interest\n",
    "combined_df = combined_df[combined_df.component.isin(viz_components)].reset_index(drop=True)\n",
    "\n",
    "# plot combined data \n",
    "fig, axes = plt.subplots(len(viz_components), 3, figsize=(15, len(viz_components)*2), sharex='col', sharey='col')\n",
    "for i, comp in enumerate(viz_components):\n",
    "    for j, mode in enumerate(modes[:3]):\n",
    "        plot_df = combined_df[combined_df.component.eq(comp) & combined_df['mode'].eq(mode)]\n",
    "        sns.barplot(plot_df, x='Label', y='Weights', errorbar='sd', color=sns.color_palette()[j+1], ax=axes[i][j])\n",
    "        if not i:\n",
    "            axes[i][j].set(title=mode)\n",
    "        if not j:\n",
    "            axes[i][j].set(ylabel=f\"Component {comp}\\n\\nWeights\")\n",
    "        if comp == viz_components[-1]:\n",
    "            axes[i][j].tick_params(axis='x', labelrotation=90); \n",
    "            axes[i][j].set(xlabel=mode);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
