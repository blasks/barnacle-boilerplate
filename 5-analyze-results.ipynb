{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Analyze final Barnacle model\n",
    "\n",
    "Use this notebook to compile and analyze the final version of your Barnacle model. This should be the version of the model that is fit with the optimal parameters you identified in step 4. There are several parts of this compilation and analysis notebook:\n",
    "1. Align the components between bootstraps of your final model.\n",
    "    - The order of components is not fixed in this tensor decomposition model. Therefore, in order to compare between bootstraps, the components must first be aligned to one another.\n",
    "    - The aligned bootstraps will be saved as an xarray.DataSet so that you can access them for further analysis\n",
    "1. Summarize the model weights for each component.\n",
    "    - Each component can be understood to model a different pattern in the data. Depending on how you set up your data and your Barnacle model, each pattern might also be associated with a different cluster (e.g. gene clusters). This step separates out each component so you can more closely examine the pattern and/or cluster each is modeling.\n",
    "1. Visualize your model.\n",
    "    - Effective visualization depends on your data type, size, dimensions, and the questions you are asking. A few potential visualizations are suggested below to help get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorly as tl\n",
    "import tlviz\n",
    "import xarray as xr\n",
    "\n",
    "from barnacle.tensors import SparseCPTensor\n",
    "from barnacle.utils import subset_cp_tensor\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "from tlab.cp_tensor import load_cp_tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# set color palette\n",
    "sns.set_palette(sns.color_palette([\n",
    "    '#9B5DE5', '#FFAC69', '#00C9AE', '#FD3F92', '#0F0A0A', '#959AB1', '#FFDB66', '#FFB1CA', '#63B9FF', '#4F1DD7'\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Align model bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUTS -- edit these variables as needed\n",
    "\n",
    "# path to directory where the outputs from your parameter search were saved (e.g. 'directory/barnacle/fitting/')\n",
    "fitpath = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/iron_KOs.txt-tidy_all_trim/sub_taxa_01/barnacle/fitting'\n",
    "\n",
    "# path to the normalized data tensor used to fit barnacle (e.g. 'directory/data-tensor.nc')\n",
    "datapath = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/iron_KOs.txt-tidy_all_trim/sub_taxa_01/data-tensor.nc'\n",
    "\n",
    "# optimal rank parameter (number of components) used to fit your final model\n",
    "optimal_rank = 100\n",
    "\n",
    "# optimal lambda parameter (sparsity coefficient) used to fit your final model\n",
    "optimal_lambda = 1.0\n",
    "\n",
    "# number of bootstraps used for final model\n",
    "n_bootstraps = 10\n",
    "\n",
    "# output directory where files produced by this notebook will be saved\n",
    "outdir = fitpath.strip('fitting') + 'model'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.makedirs(outdir)\n",
    "print(f\"File outputs of this notebook will be saved here: {outdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align bootstraps of final model\n",
    "\n",
    "# set up parameters and data structures\n",
    "input_ds = xr.load_dataset(f\"{fitpath}/bootstrap0/dataset-bootstrap0.nc\")\n",
    "replicates = [str(l) for l in set(input_ds.replicate_id.data)]\n",
    "bootstraps = np.arange(n_bootstraps)\n",
    "samplenames = {rep: [] for rep in replicates}    # sample names\n",
    "cps = {rep: [] for rep in replicates}   # cp tensors with all samples present\n",
    "subset_cps = {rep: [] for rep in replicates}    # cp tensors subset to just common samples\n",
    "\n",
    "# collect sample names of each bootstrap/replicate pair\n",
    "for boot in tqdm(bootstraps, desc='Extracting sample names'):\n",
    "    for rep in replicates:\n",
    "        ds = xr.open_dataset(f\"{fitpath}/bootstrap{boot}/replicate{rep}/shuffled-replicate-{rep}.nc\")\n",
    "        samplenames[rep].append(ds.sample_id.data)\n",
    "# compile set of samplenames common to all bootstrap / replicate splits\n",
    "samplenames['common'] = reduce(np.intersect1d, itertools.chain.from_iterable([samplenames[r] for r in replicates]))\n",
    "\n",
    "# import all fitted models\n",
    "for boot in tqdm(bootstraps, desc='Importing model bootstraps'):\n",
    "    for rep in replicates:\n",
    "        # put together data path\n",
    "        path_cp = f\"bootstrap{boot}/replicate{rep}/rank{optimal_rank}/lambda{optimal_lambda}/fitted-model.h5\"\n",
    "        # store normalized cp tensor to cps\n",
    "        cp = tl.cp_normalize(load_cp_tensor(f\"{fitpath}/{path_cp}\"))\n",
    "        cps[rep].append(cp)\n",
    "        # pull out common samplenames and store in subset_aligned_cps\n",
    "        idx = np.where(np.isin(samplenames[rep][boot], samplenames['common']))[0]\n",
    "        subset_cps[rep].append(subset_cp_tensor(cp, {2: idx}))\n",
    "print(f\"Successfully imported {len(cps[rep])} model bootstraps, each with {len(replicates)} replicates.\")\n",
    "\n",
    "# find best representative reference cp tensor\n",
    "results = []\n",
    "combos = list(itertools.product(replicates, bootstraps))\n",
    "for ref_rep, ref_boot in tqdm(combos, desc='Identifying best reference model from bootstraps'):\n",
    "    # limit comparisons to a random sample of 100 bootstraps\n",
    "    if len(combos) > 100:\n",
    "        combos = [combos[i] for i in np.random.choice(len(combos), size=100, replace=False)]\n",
    "    for comp_rep, comp_boot in combos:\n",
    "        # no point in comparing to self\n",
    "        if ref_rep == comp_rep and ref_boot == comp_boot:\n",
    "            continue\n",
    "        reference_cp = subset_cps[ref_rep][ref_boot]\n",
    "        comparison_cp = subset_cps[comp_rep][comp_boot]\n",
    "        fms = tlviz.factor_tools.factor_match_score(reference_cp, comparison_cp, consider_weights=False)\n",
    "        results.append({\n",
    "            'reference_bootstrap': ref_boot, \n",
    "            'reference_replicate': ref_rep, \n",
    "            'comparison_bootstrap': comp_boot, \n",
    "            'comparison_replicate': comp_rep, \n",
    "            'fms': fms, \n",
    "        })\n",
    "# summarize overall mean fms  \n",
    "fms_df = pd.DataFrame(results)\n",
    "fms_summary_df = fms_df.groupby([\n",
    "    'reference_bootstrap', \n",
    "    'reference_replicate'\n",
    "]).agg(\n",
    "    mean_fms=('fms', 'mean'), \n",
    "    median_fms=('fms', 'median'), \n",
    ").reset_index()\n",
    "# find the best representative bootstrap model based on maximum mean FMS\n",
    "best_ref = fms_summary_df.iloc[fms_summary_df.mean_fms.idxmax(), :]\n",
    "print('All bootstraps will be aligned to the following reference model:')\n",
    "display(pd.DataFrame(best_ref).T.reset_index(drop=True))\n",
    "\n",
    "# permute reference cp so that components are in descending order of explaned variation\n",
    "ref_cp = tlviz.factor_tools.permute_cp_tensor(\n",
    "    subset_cps[best_ref['reference_replicate']][best_ref['reference_bootstrap']], \n",
    "    consider_weights=False\n",
    ")        \n",
    "\n",
    "# realign all the other cp tensors against the best representative cp tensor\n",
    "for rep in replicates:\n",
    "    for boot in bootstraps:\n",
    "        # permute components to line up with best representative reference cp\n",
    "        perm = tlviz.factor_tools.get_cp_permutation(subset_cps[rep][boot], reference_cp_tensor=ref_cp, consider_weights=False)\n",
    "        cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(cps[rep][boot], permutation=perm)\n",
    "        subset_cps[rep][boot] = tlviz.factor_tools.permute_cp_tensor(subset_cps[rep][boot], permutation=perm)\n",
    "print('All model bootstraps successfully aligned.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile aligned model weights into a single xarray.Dataset\n",
    "\n",
    "# set up data structures\n",
    "component_labels = np.arange(optimal_rank) + 1 # 1-based indexing for ease of communication\n",
    "weights = {'mode0': [], 'mode1': [], 'component': [], 'pct_var': [], 'fms': []}\n",
    "sample_info_df = pd.merge(\n",
    "    input_ds.sample_id.to_series().reset_index(), \n",
    "    input_ds.replicate_id.to_series().reset_index(), \n",
    "    on='sample_replicate_id', how='inner'\n",
    ")[['sample_id', 'replicate_id']].rename(columns={'sample_id': 'sample', 'replicate_id': 'replicate'})\n",
    "sample_df = pd.DataFrame()\n",
    "\n",
    "# separate out reference components for component specific FMS score\n",
    "ref_components = SparseCPTensor(ref_cp).get_components()\n",
    "\n",
    "# pull model weights from each bootstrap\n",
    "for boot in tqdm(bootstraps, desc='Compiling weights from each bootstrap'):\n",
    "    boot_sample_df = pd.DataFrame()\n",
    "    for key in weights.keys():\n",
    "        weights[key].append([])\n",
    "    for rep in replicates:\n",
    "        # fetch aligned cp tensor\n",
    "        cp = cps[rep][boot]\n",
    "        # add mode 0 weights to list\n",
    "        weights['mode0'][boot].append(cp.factors[0].T)\n",
    "        # add mode 1 weights to list\n",
    "        weights['mode1'][boot].append(cp.factors[1].T)\n",
    "        # add component weights to list\n",
    "        weights['component'][boot].append(cp.weights)\n",
    "        # calculate percent variation explained by components and add to list\n",
    "        weights['pct_var'][boot].append(tlviz.factor_tools.percentage_variation(cp, dataset=input_ds.data.data, method='data'))\n",
    "        # put mode 2 (sample) weights into a pd.DataFrame\n",
    "        rep_sample_df = pd.DataFrame(\n",
    "            cp.factors[2], index=samplenames[rep][boot], columns=component_labels\n",
    "        ).reset_index().rename(columns={'index': 'sample'})\n",
    "        rep_sample_df['replicate'] = rep\n",
    "        # concatenate sample weights of all replicates\n",
    "        boot_sample_df = pd.concat([boot_sample_df, rep_sample_df])\n",
    "        # calculate component specific FMS for each component vs reference bootstrap\n",
    "        fms_scores = []\n",
    "        for i, comp_component in enumerate(SparseCPTensor(subset_cps[rep][boot]).get_components()):\n",
    "            # skip the None-type components included for aligning smaller cp tensors\n",
    "            if np.all(np.isnan(comp_component.factors[0])):\n",
    "                continue\n",
    "            # compare components\n",
    "            fms_scores.append(tlviz.factor_tools.factor_match_score(comp_component, ref_components[i], consider_weights=False))\n",
    "        weights['fms'][boot].append(fms_scores)\n",
    "    # merge sample info into sample weights dataframe\n",
    "    boot_sample_df = pd.merge(left=sample_info_df, right=boot_sample_df, on=['sample', 'replicate'], how='left')\n",
    "    boot_sample_df['bootstrap'] = boot\n",
    "    # concatenate sample weights of all bootstraps\n",
    "    sample_df = pd.concat([sample_df, boot_sample_df])\n",
    "\n",
    "# compile everything into an xarray.Dataset\n",
    "modes = list(input_ds.coords)\n",
    "modes[2] = 'sample'\n",
    "ds = xr.Dataset({\n",
    "    f\"{modes[0]}_weights\": xr.DataArray(\n",
    "        np.array(weights['mode0']), \n",
    "        coords=[bootstraps, replicates, component_labels, input_ds[modes[0]].data], \n",
    "        dims=['bootstrap', 'replicate', 'component', modes[0]]\n",
    "    ), \n",
    "    f\"{modes[1]}_weights\": xr.DataArray(\n",
    "        np.array(weights['mode1']), \n",
    "        coords=[bootstraps, replicates, component_labels, input_ds[modes[1]].data], \n",
    "        dims=['bootstrap', 'replicate', 'component', modes[1]]\n",
    "    ), \n",
    "    f\"{modes[2]}_weights\": xr.DataArray.from_series(\n",
    "        sample_df.melt(\n",
    "            id_vars=['bootstrap', 'replicate', modes[2]], \n",
    "            value_vars=component_labels, \n",
    "            var_name='component', \n",
    "            value_name='sample_weights'\n",
    "        ).set_index(['bootstrap', 'replicate', 'component', modes[2]])[f\"{modes[2]}_weights\"]\n",
    "    ), \n",
    "    'component_weights': xr.DataArray(\n",
    "            np.array(weights['component']), \n",
    "            coords=[bootstraps, replicates, component_labels], \n",
    "            dims=['bootstrap', 'replicate', 'component']\n",
    "    ),\n",
    "    'percent_variation': xr.DataArray(\n",
    "            np.array(weights['pct_var']), \n",
    "            coords=[bootstraps, replicates, component_labels], \n",
    "            dims=['bootstrap', 'replicate', 'component']\n",
    "    ), \n",
    "    'fms_component': xr.DataArray(\n",
    "            np.array(weights['fms']), \n",
    "            coords=[bootstraps, replicates, component_labels], \n",
    "            dims=['bootstrap', 'replicate', 'component']\n",
    "    )\n",
    "})\n",
    "\n",
    "# add reference tensor, rank, and sparsity coefficient as attributes\n",
    "ds.attrs['rank'] = optimal_rank\n",
    "ds.attrs['lambda'] = optimal_lambda\n",
    "ds.attrs['n_bootstraps'] = n_bootstraps\n",
    "ds.attrs['align_ref_bootstrap'] = best_ref['reference_bootstrap']\n",
    "ds.attrs['align_ref_replicate'] = best_ref['reference_replicate']\n",
    "\n",
    "# save Dataset as netCDF4 file\n",
    "ds.to_netcdf(f\"{outdir}/aligned-bootstraps.nc\")\n",
    "\n",
    "# examine Dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Summarize model weights for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component=3\n",
    "mode='KO'\n",
    "df = pd.DataFrame({\n",
    "    'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "}).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.fms_component.sel(component=1).values.ravel().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model weights for each component, and save summaries as csv files\n",
    "\n",
    "# summarize weights across bootstraps and replicates\n",
    "mean_ds = ds.mean(dim=['bootstrap', 'replicate'])    # mean of weights\n",
    "std_ds = ds.std(dim=['bootstrap', 'replicate'])    # standard deviation of weights\n",
    "med_ds = ds.median(dim=['bootstrap', 'replicate'])    # median of weights\n",
    "support_ds = (ds != 0).mean(dim=['bootstrap', 'replicate']) * 100     # bootstrap support (percent of weights nonzero)\n",
    "\n",
    "# plot % variation explained and FMS for each component \n",
    "fig, axes = plt.subplots(2, 1, figsize=(min(15, len(ds.component.data)), 10), sharex=True)\n",
    "sns.boxplot(ds.percent_variation.to_series().reset_index(), x='component', y='percent_variation', ax=axes[0]); \n",
    "axes[0].set(title='Explanatory Power of Components', xlabel='Component', ylabel='% Variation Explained'); \n",
    "sns.boxplot(ds.fms_component.to_series().reset_index(), x='component', y='fms_component', color=sns.color_palette()[8], ax=axes[1]); \n",
    "axes[1].set(title='Consistency of Components\\n(Between Bootstraps)', xlabel='Component', ylabel='FMS\\n(Relative to Alignment Reference)'); \n",
    "plt.show()\n",
    "\n",
    "# extract summary of weights for each component\n",
    "for component in ds.component.data:\n",
    "    if not os.path.isdir(f\"{outdir}/component{component}\"):\n",
    "        os.makedirs(f\"{outdir}/component{component}\")\n",
    "    for i, mode in enumerate(modes):\n",
    "        # make dataframe summarizing weights\n",
    "        df = pd.DataFrame({\n",
    "            'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        }).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "        # drop values with a median weight of zero (equivalent to 50% bootstrap support threshold)\n",
    "        df = df[~df.median_weight.eq(0)].reset_index()\n",
    "        # df = df[~df.mean_weight.eq(0)].reset_index()\n",
    "        # save data\n",
    "        df.to_csv(f\"{outdir}/component{component}/{mode}_weights_summary.csv\", index=False)\n",
    "        # plot top weights\n",
    "        if component <= max_components:\n",
    "            df = df.head(max_elements) # just look at top weights\n",
    "            df[mode] = df[mode].astype(str) # in case labels aren't strings\n",
    "            print(df[mode].values.tolist())\n",
    "            fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "            sns.barplot(df, x=mode, y='mean_weight', color=sns.color_palette()[i+1], legend=False, ax=axis); \n",
    "            axis.errorbar(x=df[mode], y=df['mean_weight'], yerr=df['std_weight'], fmt='none', color=sns.color_palette()[5])\n",
    "            axis.set(title=f\"Component {component} Top {mode.capitalize()} Weights\", xlabel=None, ylabel='Weight'); \n",
    "            fig.autofmt_xdate(rotation=90)\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get components with multiple taxa and high mean FMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_mult = []\n",
    "for component in ds.component.data:\n",
    "    mode = 'taxon_trim'\n",
    "    df = pd.DataFrame({\n",
    "        'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "    }).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "    w0, w1 = df['mean_weight'][:2].values\n",
    "    mean_fms = ds.fms_component.sel(component=component).values.ravel().mean()\n",
    "    if ((w0 * 0.4) < w1) and (mean_fms > 0.5):\n",
    "        print(f\"\\n\\nComponent: {component}\")\n",
    "        print(f\"Mean FMS: {mean_fms}\")\n",
    "        print(df['mean_weight'][:5])\n",
    "        comp_mult.append(component)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract summary of weights for each component\n",
    "for component in comp_mult:\n",
    "    mean_fms = ds.fms_component.sel(component=component).values.ravel().mean()\n",
    "    print(f\"\\n\\nComponent: {component}\")\n",
    "    print(f\"Mean FMS: {mean_fms}\")\n",
    "    if not os.path.isdir(f\"{outdir}/component{component}\"):\n",
    "        os.makedirs(f\"{outdir}/component{component}\")\n",
    "    for i, mode in enumerate(modes):\n",
    "        # make dataframe summarizing weights\n",
    "        df = pd.DataFrame({\n",
    "            'mean_weight': mean_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'std_weight': std_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'median_weight': med_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "            'pct_bootstraps_nonzero': support_ds.sel(component=component)[f\"{mode}_weights\"].to_series(), \n",
    "        }).sort_values(by=['mean_weight', 'pct_bootstraps_nonzero'], key=abs, ascending=False)\n",
    "        # drop values with a median weight of zero (equivalent to 50% bootstrap support threshold)\n",
    "        df = df[~df.median_weight.eq(0)].reset_index()\n",
    "        # df = df[~df.mean_weight.eq(0)].reset_index()\n",
    "        # save data\n",
    "        df.to_csv(f\"{outdir}/component{component}/{mode}_weights_summary.csv\", index=False)\n",
    "        # plot top weights\n",
    "        df = df.head(max_elements) # just look at top weights\n",
    "        df[mode] = df[mode].astype(str) # in case labels aren't strings\n",
    "        print(df[mode].values.tolist())\n",
    "        fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "        sns.barplot(df, x=mode, y='mean_weight', color=sns.color_palette()[i+1], legend=False, ax=axis); \n",
    "        axis.errorbar(x=df[mode], y=df['mean_weight'], yerr=df['std_weight'], fmt='none', color=sns.color_palette()[5])\n",
    "        axis.set(title=f\"Component {component} Top {mode.capitalize()} Weights\", xlabel=None, ylabel='Weight'); \n",
    "        fig.autofmt_xdate(rotation=90)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare weight profiles between components\n",
    "\n",
    "# make dataframe for concatenating weight profiles\n",
    "concat_profile_df = pd.DataFrame()\n",
    "\n",
    "# iterate through comparisons\n",
    "comparisons = modes + ['concatenated']\n",
    "# Dict for storing linkage calculations\n",
    "links = {}\n",
    "columns = {}\n",
    "for mode in comparisons:\n",
    "    print(f\"Comparing {mode} weights:\")\n",
    "    if mode != 'concatenated':\n",
    "        # calculate median weight profile for each component in model\n",
    "        profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "        # add mode weight profile to concatenated profile\n",
    "        concat_profile_df = pd.concat([concat_profile_df, profile_df], axis=1)\n",
    "    else:\n",
    "        profile_df = concat_profile_df\n",
    "    # calculate correlation matrix\n",
    "    corr_df = profile_df.T.corr()\n",
    "    # Precalculate linkage to extract clusters later\n",
    "    link = hierarchy.linkage(distance.pdist(np.asarray(corr_df)))\n",
    "    links[mode] = link\n",
    "    columns[mode] = profile_df.columns\n",
    "    # make clustered heatmap\n",
    "    # using precalculated linkage\n",
    "    g = sns.clustermap(\n",
    "        corr_df.fillna(0), \n",
    "        row_linkage=link, col_linkage=link,\n",
    "        mask=corr_df.isna(), \n",
    "        cmap='PuOr_r', vmin=-1, vmax=1, \n",
    "        cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "        xticklabels=True, yticklabels=True\n",
    "    )\n",
    "    # g = sns.clustermap(\n",
    "    #     corr_df.fillna(0), mask=corr_df.isna(), cmap='PuOr_r', vmin=-1, vmax=1, cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "    #     xticklabels=True, yticklabels=True\n",
    "    # )\n",
    "    g.fig.suptitle(f\"Similarity of {mode.capitalize()} Weights Between Components\", y=1.02); \n",
    "    plt.show(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get taxon clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'taxon_trim'\n",
    "t = 20\n",
    "clust = hierarchy.fcluster(links[mode], t=t, criterion='maxclust')\n",
    "profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "\n",
    "cmap = plt.get_cmap('tab20').colors\n",
    "lut = dict(zip(np.unique(clust), cmap))\n",
    "# idx_df = hierarchy.leaves_list(links[mode])\n",
    "row_colors = [lut[cl] for cl in clust]\n",
    "\n",
    "# calculate correlation matrix\n",
    "corr_df = profile_df.T.corr()\n",
    "# Precalculate linkage to extract clusters later\n",
    "link = hierarchy.linkage(distance.pdist(np.asarray(corr_df)))\n",
    "links[mode] = link\n",
    "columns[mode] = profile_df.columns\n",
    "# make clustered heatmap\n",
    "# using precalculated linkage\n",
    "g = sns.clustermap(\n",
    "    corr_df.fillna(0), \n",
    "    row_linkage=link, col_linkage=link,\n",
    "    row_colors=row_colors,\n",
    "    col_colors=row_colors,\n",
    "    mask=corr_df.isna(), \n",
    "    cmap='PuOr_r', vmin=-1, vmax=1, \n",
    "    cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "    xticklabels=True, yticklabels=True\n",
    ")\n",
    "# g = sns.clustermap(\n",
    "#     corr_df.fillna(0), mask=corr_df.isna(), cmap='PuOr_r', vmin=-1, vmax=1, cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "#     xticklabels=True, yticklabels=True\n",
    "# )\n",
    "g.fig.suptitle(f\"Similarity of {mode.capitalize()} Weights Between Components\", y=1.02); \n",
    "plt.show(g)\n",
    "\n",
    "\n",
    "for cl in np.unique(clust):\n",
    "    color = lut[cl]\n",
    "    bool_cl = clust == cl\n",
    "    profile_cl = profile_df[bool_cl]\n",
    "    print(profile_cl.index)\n",
    "\n",
    "    pcl_mean = profile_cl.mean(axis=0).rename('mean')\n",
    "    pcl_std = profile_cl.std(axis=0).rename('std')\n",
    "    pcl_ms = pd.concat([pcl_mean, pcl_std], axis=1).T\n",
    "    profile_cl = pd.concat(\n",
    "        [profile_cl, pcl_ms], axis=0\n",
    "    ).T\n",
    "    profile_cl.index = profile_cl.index.map(str)\n",
    "    fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "    sns.barplot(profile_cl, x=mode, y='mean', color=color, legend=False, ax=axis); \n",
    "    axis.errorbar(x=profile_cl.index, y=profile_cl['mean'], yerr=profile_cl['std'], fmt='none', color=sns.color_palette()[5])\n",
    "    axis.set(title=f\"Cluster {cl} Top {mode.capitalize()} Mean Weights\", xlabel=None, ylabel='Weight'); \n",
    "    fig.autofmt_xdate(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkn = {'K00265': 'K00265  gltB; glutamate synthase (NADPH) large chain [EC:1.4.1.13]',\n",
    " 'K01012': 'K01012  bioB; biotin synthase [EC:2.8.1.6]',\n",
    " 'K01595': 'K01595  ppc; phosphoenolpyruvate carboxylase [EC:4.1.1.31]',\n",
    " 'K01672': 'K01672  CA; carbonic anhydrase [EC:4.2.1.1]',\n",
    " 'K01726': 'K01726  GAMMACA; gamma-carbonic anhydrase [EC:4.2.1.-]',\n",
    " 'K02217': 'K02217  ftnA, ftn; ferritin [EC:1.16.3.2]',\n",
    " 'K02255': 'K02255  ftnB; ferritin-like protein 2',\n",
    " 'K02364': 'K02364  entF; L-serine---[L-seryl-carrier protein] ligase [EC:6.3.2.14 6.2.1.72]',\n",
    " 'K02638': 'K02638  petE; plastocyanin',\n",
    " 'K02639': 'K02639  petF; ferredoxin',\n",
    " 'K03320': 'K03320  amt, AMT, MEP; ammonium transporter, Amt family',\n",
    " 'K04564': 'K04564  SOD2; superoxide dismutase, Fe-Mn family [EC:1.15.1.1]',\n",
    " 'K04641': 'K04641  bop; bacteriorhodopsin',\n",
    " 'K04783': 'K04783  irp5, ybtE; yersiniabactin salicyl-AMP ligase [EC:6.3.2.-]',\n",
    " 'K04784': 'K04784  irp2, HMWP2; yersiniabactin nonribosomal peptide synthetase',\n",
    " 'K05524': 'K05524  fdxA; ferredoxin',\n",
    " 'K07214': 'K07214  fes; iron(III)-enterobactin esterase [EC:3.1.1.108]',\n",
    " 'K12237': 'K12237  vibF; nonribosomal peptide synthetase VibF',\n",
    " 'K16087': 'K16087  TC.FEV.OM3, tbpA, hemR, lbpA, hpuB, bhuR, hugA, hmbR; hemoglobin/transferrin/lactoferrin receptor protein',\n",
    " 'K19611': 'K19611  fepA, pfeA, iroN, pirA; ferric enterobactin receptor',\n",
    " 'K22336': 'K22336  bfrB; bacterioferritin B [EC:1.16.3.1]',\n",
    " 'K22552': 'K22552  mmcO; multicopper oxidase [EC:1.16.3.1]',\n",
    " 'K23910': 'K23910  TFR2; transferrin receptor protein 2',\n",
    " 'K25224': 'K25224  gapdh; glyceraldehyde-3-phosphate dehydrogenase (arsenate-transferring) [EC:1.2.1.107]'}\n",
    "dtn = {\n",
    "    '226': 'Alteromonas',\n",
    "    '2864': 'Dinophyceae',\n",
    "    '3041': 'Chlorophyta',\n",
    "    '28211': 'Alphaproteobacteria',\n",
    "    '31989': 'Paracoccaceae',\n",
    "    '35127': 'Thalassiosira',\n",
    "    '35677': 'Pelagomonas calceolata',\n",
    "    '49546': 'Flavobacteriaceae',\n",
    "    '135623': 'Vibrionales',\n",
    "    '304208': \"Pseudoalteromonas sp. '520P1 No. 412'\",\n",
    "    '487796': 'Flavobacteria bacterium MS024-2A',\n",
    "    '1735725': 'Stramenopiles MAST-4',\n",
    "    '2696291': 'Ochrophyta',\n",
    "    '2854170': 'Roseobacteraceae'\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_select = [1,4]\n",
    "# cl_select = [7, 17]\n",
    "threshs = {\n",
    "    'KO':0.2,\n",
    "    'taxon_trim':0.1,\n",
    "    'sample': 0.2,\n",
    "    'mean_fms': 0.3\n",
    "}\n",
    "for cl in cl_select:\n",
    "    print(cl)\n",
    "    for i, mode in enumerate(modes):\n",
    "        print(mode)\n",
    "        profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "        bool_cl = clust == cl\n",
    "        profile_cl = profile_df[bool_cl]\n",
    "        pcl_max = np.abs(profile_cl).max(axis=0).rename('max')\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.scatter(np.arange(pcl_max.shape[0]), pcl_max.sort_values(), color=color)\n",
    "        # plt.show()\n",
    "        bool_mode = pcl_max >= threshs[mode]\n",
    "        pcl_sub = profile_cl.loc[:,bool_mode]\n",
    "        # print(pcl_sub.columns)\n",
    "\n",
    "        df = ds.sel({mode: ds[mode]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "        df = df[\n",
    "            df.component.isin(pcl_sub.index) \n",
    "            & df[mode].isin(pcl_sub.columns)\n",
    "        ]\n",
    "        mfms = []\n",
    "        for c in pcl_sub.index:\n",
    "            mean_fms = ds.fms_component.sel(component=c).values.ravel().mean()\n",
    "            mfms.append(mean_fms)\n",
    "        print(dict(zip(pcl_sub.index, mfms)))\n",
    "        if mode == 'KO':\n",
    "            df[mode] = [dkn[k] for k in df[mode]]\n",
    "        if mode == 'taxon_trim':\n",
    "            df[mode] = [dtn[str(t)] for t in df[mode]]\n",
    "        g = sns.FacetGrid(df, row='component', aspect=5)\n",
    "        g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "        g.fig.suptitle(f\"Cluster {cl} {mode.capitalize()} Component Weights > {threshs[mode]}\", y = 1.005); \n",
    "        g.set_xticklabels(df[mode].unique(), rotation=45, ha='right'); \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'sample'\n",
    "max_sam = 10\n",
    "t = 20\n",
    "clust = hierarchy.fcluster(links[mode], t=t, criterion='maxclust')\n",
    "profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "\n",
    "cmap = plt.get_cmap('tab20').colors\n",
    "lut = dict(zip(np.unique(clust), cmap))\n",
    "# idx_df = hierarchy.leaves_list(links[mode])\n",
    "row_colors = [lut[cl] for cl in clust]\n",
    "\n",
    "# calculate correlation matrix\n",
    "corr_df = profile_df.T.corr()\n",
    "# Precalculate linkage to extract clusters later\n",
    "link = hierarchy.linkage(distance.pdist(np.asarray(corr_df)))\n",
    "links[mode] = link\n",
    "columns[mode] = profile_df.columns\n",
    "# make clustered heatmap\n",
    "# using precalculated linkage\n",
    "g = sns.clustermap(\n",
    "    corr_df.fillna(0), \n",
    "    row_linkage=link, col_linkage=link,\n",
    "    row_colors=row_colors,\n",
    "    col_colors=row_colors,\n",
    "    mask=corr_df.isna(), \n",
    "    cmap='PuOr_r', vmin=-1, vmax=1, \n",
    "    cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "    xticklabels=True, yticklabels=True\n",
    ")\n",
    "# g = sns.clustermap(\n",
    "#     corr_df.fillna(0), mask=corr_df.isna(), cmap='PuOr_r', vmin=-1, vmax=1, cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "#     xticklabels=True, yticklabels=True\n",
    "# )\n",
    "g.fig.suptitle(f\"Similarity of {mode.capitalize()} Weights Between Components\", y=1.02); \n",
    "plt.show(g)\n",
    "\n",
    "\n",
    "for cl in np.unique(clust):\n",
    "    color = lut[cl]\n",
    "    bool_cl = clust == cl\n",
    "    profile_cl = profile_df[bool_cl]\n",
    "    print(profile_cl.index)\n",
    "\n",
    "\n",
    "    pcl_mean = profile_cl.mean(axis=0).rename('mean')\n",
    "    pcl_std = profile_cl.std(axis=0).rename('std')\n",
    "    pcl_ms = pd.concat([pcl_mean, pcl_std], axis=1).T\n",
    "    profile_cl = pd.concat(\n",
    "        [profile_cl, pcl_ms], axis=0\n",
    "    ).T.sort_values(by='mean',ascending=False)[:max_sam]\n",
    "    profile_cl.index = profile_cl.index.map(str)\n",
    "    fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "    sns.barplot(profile_cl, x=mode, y='mean', color=color, legend=False, ax=axis); \n",
    "    axis.errorbar(x=profile_cl.index, y=profile_cl['mean'], yerr=profile_cl['std'], fmt='none', color=sns.color_palette()[5])\n",
    "    axis.set(title=f\"Cluster {cl} Top {mode.capitalize()} Mean Weights\", xlabel=None, ylabel='Weight'); \n",
    "    fig.autofmt_xdate(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkn = {'K00265': 'K00265  gltB; glutamate synthase (NADPH) large chain [EC:1.4.1.13]',\n",
    " 'K00368': 'K00368  nirK; nitrite reductase (NO-forming) [EC:1.7.2.1]',\n",
    " 'K00615': 'K00615  E2.2.1.1, tktA, tktB; transketolase [EC:2.2.1.1]',\n",
    " 'K00855': 'K00855  PRK, prkB; phosphoribulokinase [EC:2.7.1.19]',\n",
    " 'K01012': 'K01012  bioB; biotin synthase [EC:2.8.1.6]',\n",
    " 'K01601': 'K01601  rbcL, cbbL; ribulose-bisphosphate carboxylase large chain [EC:4.1.1.39]',\n",
    " 'K01602': 'K01602  rbcS, cbbS; ribulose-bisphosphate carboxylase small chain [EC:4.1.1.39]',\n",
    " 'K01624': 'K01624  FBA, fbaA; fructose-bisphosphate aldolase, class II [EC:4.1.2.13]',\n",
    " 'K01672': 'K01672  CA; carbonic anhydrase [EC:4.2.1.1]',\n",
    " 'K01673': 'K01673  cynT, can; carbonic anhydrase [EC:4.2.1.1]',\n",
    " 'K02364': 'K02364  entF; L-serine---[L-seryl-carrier protein] ligase [EC:6.3.2.14 6.2.1.72]',\n",
    " 'K02639': 'K02639  petF; ferredoxin',\n",
    " 'K02689': 'K02689  psaA; photosystem I P700 chlorophyll a apoprotein A1 [EC:1.97.1.12]',\n",
    " 'K02695': 'K02695  psaH; photosystem I subunit VI',\n",
    " 'K02699': 'K02699  psaL; photosystem I subunit XI',\n",
    " 'K02703': 'K02703  psbA; photosystem II P680 reaction center D1 protein [EC:1.10.3.9]',\n",
    " 'K02704': 'K02704  psbB; photosystem II CP47 chlorophyll apoprotein',\n",
    " 'K02705': 'K02705  psbC; photosystem II CP43 chlorophyll apoprotein',\n",
    " 'K02706': 'K02706  psbD; photosystem II P680 reaction center D2 protein [EC:1.10.3.9]',\n",
    " 'K02708': 'K02708  psbF; photosystem II cytochrome b559 subunit beta',\n",
    " 'K02711': 'K02711  psbJ; photosystem II PsbJ protein',\n",
    " 'K02717': 'K02717  psbP; photosystem II oxygen-evolving enhancer protein 2',\n",
    " 'K02718': 'K02718  psbT; photosystem II PsbT protein',\n",
    " 'K02721': 'K02721  psbW; photosystem II PsbW protein',\n",
    " 'K02722': 'K02722  psbX; photosystem II PsbX protein',\n",
    " 'K02724': 'K02724  psbZ; photosystem II PsbZ protein',\n",
    " 'K03320': 'K03320  amt, AMT, MEP; ammonium transporter, Amt family',\n",
    " 'K03542': 'K03542  psbS; photosystem II 22kDa protein',\n",
    " 'K03594': 'K03594  bfr; bacterioferritin [EC:1.16.3.1]',\n",
    " 'K03839': 'K03839  fldA, nifF, isiB; flavodoxin I',\n",
    " 'K03841': 'K03841  FBP, fbp; fructose-1,6-bisphosphatase I [EC:3.1.3.11]',\n",
    " 'K04564': 'K04564  SOD2; superoxide dismutase, Fe-Mn family [EC:1.15.1.1]',\n",
    " 'K04565': 'K04565  SOD1; superoxide dismutase, Cu-Zn family [EC:1.15.1.1]',\n",
    " 'K04755': 'K04755  fdx; ferredoxin, 2Fe-2S',\n",
    " 'K04759': 'K04759  feoB; ferrous iron transport protein B',\n",
    " 'K04784': 'K04784  irp2, HMWP2; yersiniabactin nonribosomal peptide synthetase',\n",
    " 'K04787': 'K04787  mbtA; mycobactin salicyl-AMP ligase [EC:6.3.2.-]',\n",
    " 'K05374': 'K05374  irp4, ybtT; yersiniabactin synthetase, thioesterase component',\n",
    " 'K05524': 'K05524  fdxA; ferredoxin',\n",
    " 'K07214': 'K07214  fes; iron(III)-enterobactin esterase [EC:3.1.1.108]',\n",
    " 'K08940': 'K08940  pscA; photosystem P840 reaction center large subunit',\n",
    " 'K10850': 'K10850  narT; MFS transporter, NNP family, putative nitrate transporter',\n",
    " 'K11645': 'K11645  fbaB; fructose-bisphosphate aldolase, class I [EC:4.1.2.13]',\n",
    " 'K12237': 'K12237  vibF; nonribosomal peptide synthetase VibF',\n",
    " 'K13859': 'K13859  SLC4A8; solute carrier family 4 (sodium bicarbonate cotransporter), member 8',\n",
    " 'K13860': 'K13860  SLC4A9, AE4; solute carrier family 4 (sodium bicarbonate cotransporter), member 9',\n",
    " 'K16087': 'K16087  TC.FEV.OM3, tbpA, hemR, lbpA, hpuB, bhuR, hugA, hmbR; hemoglobin/transferrin/lactoferrin receptor protein',\n",
    " 'K21567': 'K21567  fnr; ferredoxin/flavodoxin---NADP+ reductase [EC:1.18.1.2 1.19.1.1]',\n",
    " 'K22336': 'K22336  bfrB; bacterioferritin B [EC:1.16.3.1]',\n",
    " 'K22552': 'K22552  mmcO; multicopper oxidase [EC:1.16.3.1]',\n",
    " 'K23723': 'K23723  iroD; iron(III)-salmochelin esterase [EC:3.1.1.109]',\n",
    " 'K24110': 'K24110  asbC; 3,4-dihydroxybenzoate---[aryl-carrier protein] ligase [EC:6.2.1.62]',\n",
    " 'K00264': 'K00264  GLT1; glutamate synthase (NADH) [EC:1.4.1.14]',\n",
    " 'K00266': 'K00266  gltD; glutamate synthase (NADPH) small chain [EC:1.4.1.13]',\n",
    " 'K00284': 'K00284  GLU, gltS; glutamate synthase (ferredoxin) [EC:1.4.7.1]',\n",
    " 'K00362': 'K00362  nirB; nitrite reductase (NADH) large subunit [EC:1.7.1.15]',\n",
    " 'K00522': 'K00522  FTH1; ferritin heavy chain [EC:1.16.3.1]',\n",
    " 'K00532': 'K00532  E1.12.7.2; ferredoxin hydrogenase [EC:1.12.7.2]',\n",
    " 'K02011': 'K02011  afuB, fbpB; iron(III) transport system permease protein',\n",
    " 'K02574': 'K02574  napH; ferredoxin-type protein NapH',\n",
    " 'K02697': 'K02697  psaJ; photosystem I subunit IX',\n",
    " 'K02714': 'K02714  psbM; photosystem II PsbM protein',\n",
    " 'K02716': 'K02716  psbO; photosystem II oxygen-evolving enhancer protein 1',\n",
    " 'K04641': 'K04641  bop; bacteriorhodopsin',\n",
    " 'K04786': 'K04786  irp1, HMWP1; yersiniabactin nonribosomal peptide/polyketide synthase',\n",
    " 'K06441': 'K06441  E1.12.7.2G; ferredoxin hydrogenase gamma subunit [EC:1.12.7.2]',\n",
    " 'K06503': 'K06503  TFRC, CD71; transferrin receptor',\n",
    " 'K08906': 'K08906  petJ; cytochrome c6',\n",
    " 'K11959': 'K11959  urtA; urea transport system substrate-binding protein',\n",
    " 'K13575': 'K13575  SLC4A4, NBC1; solute carrier family 4 (sodium bicarbonate cotransporter), member 4',\n",
    " 'K14578': 'K14578  nahAb, nagAb, ndoA, nbzAb, dntAb; naphthalene 1,2-dioxygenase ferredoxin component',\n",
    " 'K15579': 'K15579  nrtD, cynD; nitrate/nitrite transport system ATP-binding protein',\n",
    " 'K19611': 'K19611  fepA, pfeA, iroN, pirA; ferric enterobactin receptor',\n",
    " 'K19791': 'K19791  FET3_5; iron transport multicopper oxidase',\n",
    " 'K21949': 'K21949  sbnA; N-(2-amino-2-carboxyethyl)-L-glutamate synthase [EC:2.5.1.140]',\n",
    " 'K22338': 'K22338  hylA; formate dehydrogenase (NAD+, ferredoxin) subunit A [EC:1.17.1.11]',\n",
    " 'K22339': 'K22339  hylB; formate dehydrogenase (NAD+, ferredoxin) subunit B [EC:1.17.1.11]',\n",
    " 'K23184': 'K23184  fecE; ferric citrate transport system ATP-binding protein [EC:7.2.2.18]',\n",
    " 'K23910': 'K23910  TFR2; transferrin receptor protein 2',\n",
    " 'K25286': 'K25286  fagD, cchF, irp1A, piaA; iron-siderophore transport system substrate-binding protein',\n",
    " 'K02012': 'K02012  afuA, fbpA; iron(III) transport system substrate-binding protein',\n",
    " 'K02690': 'K02690  psaB; photosystem I P700 chlorophyll a apoprotein A2 [EC:1.97.1.12]',\n",
    " 'K00372': 'K00372  nasC,  nasA; assimilatory nitrate reductase catalytic subunit [EC:1.7.99.-]',\n",
    " 'K01595': 'K01595  ppc; phosphoenolpyruvate carboxylase [EC:4.1.1.31]',\n",
    " 'K02719': 'K02719  psbU; photosystem II PsbU protein',\n",
    " 'K02720': 'K02720  psbV; photosystem II cytochrome c550',\n",
    " 'K04783': 'K04783  irp5, ybtE; yersiniabactin salicyl-AMP ligase [EC:6.3.2.-]',\n",
    " 'K05710': 'K05710  hcaC; 3-phenylpropionate/trans-cinnamate dioxygenase ferredoxin component',\n",
    " 'K14718': 'K14718  SLC39A12, ZIP12; solute carrier family 39 (zinc transporter), member 12',\n",
    " 'K23725': 'K23725  iroB; enterobactin C-glucosyltransferase [EC:2.4.1.369]',\n",
    " 'K24245': \"K24245  ligXd; 5,5'-dehydrodivanillate O-demethylase ferredoxin reductase subunit [EC:1.18.1.-]\"}\n",
    "dtn = {\n",
    "    '226': 'Alteromonas',\n",
    "    '2864': 'Dinophyceae',\n",
    "    '3041': 'Chlorophyta',\n",
    "    '28211': 'Alphaproteobacteria',\n",
    "    '31989': 'Paracoccaceae',\n",
    "    '35127': 'Thalassiosira',\n",
    "    '35677': 'Pelagomonas calceolata',\n",
    "    '49546': 'Flavobacteriaceae',\n",
    "    '135623': 'Vibrionales',\n",
    "    '304208': \"Pseudoalteromonas sp. '520P1 No. 412'\",\n",
    "    '487796': 'Flavobacteria bacterium MS024-2A',\n",
    "    '1735725': 'Stramenopiles MAST-4',\n",
    "    '2696291': 'Ochrophyta',\n",
    "    '2854170': 'Roseobacteraceae'\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_select = [17]\n",
    "# cl_select = [7, 17]\n",
    "threshs = {\n",
    "    'KO':0.2,\n",
    "    'taxon_trim':0.2,\n",
    "    'sample': 0.2\n",
    "}\n",
    "for cl in cl_select:\n",
    "    print(cl)\n",
    "    for i, mode in enumerate(modes):\n",
    "        print(mode)\n",
    "        profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "        bool_cl = clust == cl\n",
    "        profile_cl = profile_df[bool_cl]\n",
    "        pcl_max = np.abs(profile_cl).max(axis=0).rename('max')\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.scatter(np.arange(pcl_max.shape[0]), pcl_max.sort_values(), color=color)\n",
    "        # plt.show()\n",
    "        bool_mode = pcl_max >= threshs[mode]\n",
    "        pcl_sub = profile_cl.loc[:,bool_mode]\n",
    "        # print(pcl_sub.columns)\n",
    "\n",
    "        df = ds.sel({mode: ds[mode]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "        df = df[\n",
    "            df.component.isin(pcl_sub.index) \n",
    "            & df[mode].isin(pcl_sub.columns)\n",
    "        ]\n",
    "        if mode == 'KO':\n",
    "            df[mode] = [dkn[k] for k in df[mode]]\n",
    "            for i, row in pcl_sub.iterrows():\n",
    "                mean_fms = ds.fms_component.sel(component=i).values.ravel().mean()\n",
    "                print(f\"Component {i}\")\n",
    "                print(f\"Mean FMS {round(mean_fms,2)}\")\n",
    "                for k, v in row.items():\n",
    "                    if v > 0.1:\n",
    "                        print(round(v, 2), dkn[k])\n",
    "        if mode == 'taxon_trim':\n",
    "            df[mode] = [dtn[str(t)] for t in df[mode]]\n",
    "        g = sns.FacetGrid(df, row='component', aspect=5)\n",
    "        g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "        g.fig.suptitle(f\"Cluster {cl} {mode.capitalize()} Component Weights > {threshs[mode]}\", y = 1.005); \n",
    "        g.set_xticklabels(df[mode].unique(), rotation=45, ha='right'); \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get KO clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'KO'\n",
    "max_sam = 10\n",
    "t = 15\n",
    "clust = hierarchy.fcluster(links[mode], t=t, criterion='maxclust')\n",
    "profile_df = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).to_pandas()\n",
    "\n",
    "cmap = plt.get_cmap('tab20').colors\n",
    "lut = dict(zip(np.unique(clust), cmap))\n",
    "# idx_df = hierarchy.leaves_list(links[mode])\n",
    "row_colors = [lut[cl] for cl in clust]\n",
    "\n",
    "# calculate correlation matrix\n",
    "corr_df = profile_df.T.corr()\n",
    "# Precalculate linkage to extract clusters later\n",
    "link = hierarchy.linkage(distance.pdist(np.asarray(corr_df)))\n",
    "links[mode] = link\n",
    "columns[mode] = profile_df.columns\n",
    "# make clustered heatmap\n",
    "# using precalculated linkage\n",
    "g = sns.clustermap(\n",
    "    corr_df.fillna(0), \n",
    "    row_linkage=link, col_linkage=link,\n",
    "    row_colors=row_colors,\n",
    "    col_colors=row_colors,\n",
    "    mask=corr_df.isna(), \n",
    "    cmap='PuOr_r', vmin=-1, vmax=1, \n",
    "    cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "    xticklabels=True, yticklabels=True\n",
    ")\n",
    "# g = sns.clustermap(\n",
    "#     corr_df.fillna(0), mask=corr_df.isna(), cmap='PuOr_r', vmin=-1, vmax=1, cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "#     xticklabels=True, yticklabels=True\n",
    "# )\n",
    "g.fig.suptitle(f\"Similarity of {mode.capitalize()} Weights Between Components\", y=1.02); \n",
    "plt.show(g)\n",
    "\n",
    "\n",
    "for cl in np.unique(clust):\n",
    "    color = lut[cl]\n",
    "    bool_cl = clust == cl\n",
    "\n",
    "    if sum(bool_cl) > 2:\n",
    "        profile_cl = profile_df[bool_cl]\n",
    "        print(profile_cl.index)\n",
    "\n",
    "        pcl_mean = profile_cl.mean(axis=0).rename('mean')\n",
    "        pcl_std = profile_cl.std(axis=0).rename('std')\n",
    "        pcl_ms = pd.concat([pcl_mean, pcl_std], axis=1).T\n",
    "        profile_cl = pd.concat(\n",
    "            [profile_cl, pcl_ms], axis=0\n",
    "        ).T.sort_values(by='mean',ascending=False)[:max_sam]\n",
    "        profile_cl.index = profile_cl.index.map(str)\n",
    "        print(profile_cl.index)\n",
    "        fig, axis = plt.subplots(figsize=(min(15, len(df)), 3))\n",
    "        sns.barplot(profile_cl, x=mode, y='mean', color=color, legend=False, ax=axis); \n",
    "        axis.errorbar(x=profile_cl.index, y=profile_cl['mean'], yerr=profile_cl['std'], fmt='none', color=sns.color_palette()[5])\n",
    "        axis.set(title=f\"Cluster {cl} Top {mode.capitalize()} Mean Weights\", xlabel=None, ylabel='Weight'); \n",
    "        fig.autofmt_xdate(rotation=90)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 0) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[0]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n",
    "\n",
    "\n",
    "df[mode].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 1) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[1]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n",
    "\n",
    "df[mode].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top weights (mode 2 -- sample mode) between components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 20    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "mode = modes[2]\n",
    "if heuristic == 'max_weight':\n",
    "    # weights sorted by maximum across all components\n",
    "    idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "elif heuristic == 'max_variation': \n",
    "    idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "\n",
    "# plot data, only including listed components\n",
    "g = sns.FacetGrid(df[df.component.isin(viz_components)], row='component', aspect=5)\n",
    "g.map(sns.barplot, mode, f\"{mode}_weights\", order=df[mode].unique(), color=sns.color_palette()[modes.index(mode)+1], errorbar='sd');\n",
    "g.fig.suptitle(f\"Component Weights of Top {max_elements} {mode.capitalize()}s\", y=1.02); \n",
    "g.set_xticklabels(df[mode].unique(), rotation=90); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined figure that looks at top weights across all three modes for a subset of components\n",
    "\n",
    "# USER INPUTS -- edit as needed\n",
    "max_elements = 10    # maximum number of elements visualized in any one component\n",
    "viz_components = [1, 2, 3, 4, 5]    # list components you want to compare against one another\n",
    "heuristic = 'max_weight'    # pull out the top weights across any component\n",
    "# heuristic = 'max_variation'    # pull out the weights that vary the most across components\n",
    "\n",
    "# pull out the top weights\n",
    "combined_df = pd.DataFrame()\n",
    "for mode in modes[:3]:\n",
    "    if heuristic == 'max_weight':\n",
    "        # weights sorted by maximum across all components\n",
    "        idx = np.abs(ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate'])).max(dim='component').argsort()\n",
    "    elif heuristic == 'max_variation': \n",
    "        idx = ds[f\"{mode}_weights\"].median(dim=['bootstrap', 'replicate']).std(dim='component').argsort()\n",
    "    df = ds.sel({mode: ds[mode][idx[-max_elements:].data[::-1]]})[f\"{mode}_weights\"].to_series().reset_index()\n",
    "    df = df.rename(columns={mode: 'Label', f\"{mode}_weights\": 'Weights'})\n",
    "    df['mode'] = mode\n",
    "    combined_df = pd.concat([combined_df, df], axis=0)\n",
    "# pull out just components of interest\n",
    "combined_df = combined_df[combined_df.component.isin(viz_components)].reset_index(drop=True)\n",
    "\n",
    "# plot combined data \n",
    "fig, axes = plt.subplots(len(viz_components), 3, figsize=(15, len(viz_components)*2), sharex='col', sharey='col')\n",
    "for i, comp in enumerate(viz_components):\n",
    "    for j, mode in enumerate(modes[:3]):\n",
    "        plot_df = combined_df[combined_df.component.eq(comp) & combined_df['mode'].eq(mode)]\n",
    "        sns.barplot(plot_df, x='Label', y='Weights', errorbar='sd', color=sns.color_palette()[j+1], ax=axes[i][j])\n",
    "        if not i:\n",
    "            axes[i][j].set(title=mode)\n",
    "        if not j:\n",
    "            axes[i][j].set(ylabel=f\"Component {comp}\\n\\nWeights\")\n",
    "        if comp == viz_components[-1]:\n",
    "            axes[i][j].tick_params(axis='x', labelrotation=90); \n",
    "            axes[i][j].set(xlabel=mode);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
